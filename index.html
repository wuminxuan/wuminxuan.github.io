<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>吴旻轩的个人博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="吴旻轩的个人博客">
<meta property="og:url" content="http://wuminxuan.github.io/index.html">
<meta property="og:site_name" content="吴旻轩的个人博客">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="zh-CN">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="吴旻轩的个人博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">吴旻轩的个人博客</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://wuminxuan.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-KMP" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/11/24/KMP/" class="article-date">
  <time datetime="2022-11-24T05:38:52.000Z" itemprop="datePublished">2022-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/11/24/KMP/">KMP</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>这个算法有点绕，现在搞懂了，以后还要多复习</p>
<p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html">字符串匹配的KMP算法 - 阮一峰的网络日志 (ruanyifeng.com)</a></p>
<p>​    使用next数组加速匹配，当模式串中的needle[j]!=haystack[i]时，不动i，而将j回退到next[j-1]上，因为前j-1个已经匹配上了，而next[j-1]对应的是最大相同前缀的下一个，如果此时j又匹配上了，则可以继续匹配；否则继续往前追溯。</p>
<p>​    next数组：<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221124114004865.png" alt="image-20221124114004865"></p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221124112752986.png" alt="image-20221124112752986" style="zoom:88%;" />
      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/11/24/KMP/" data-id="clbaeg539000g40tx213b0vme" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/KMP/" rel="tag">KMP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%AE%97%E6%B3%95/" rel="tag">字符串算法</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-An Empirical Study on the Usage of BERT Models for Code Completion" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/11/16/An%20Empirical%20Study%20on%20the%20Usage%20of%20BERT%20Models%20for%20Code%20Completion/" class="article-date">
  <time datetime="2022-11-16T05:36:13.000Z" itemprop="datePublished">2022-11-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/">技术论文研读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/11/16/An%20Empirical%20Study%20on%20the%20Usage%20of%20BERT%20Models%20for%20Code%20Completion/">An Empirical Study on the Usage of BERT Models for Code Completion</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>作者运用 RoBERTa 模型针对Java Code和Android Code分别使用Token masking，Construct Masking，Block masking在Raw数据和抽象处理过的Abstract数据进行了模型训练和测试，得出了2 * 3 * 2=12组结果，结果如下图。</p>
<p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221116203429606.png" alt="image-20221116203429606"></p>
<p>​    Abstract数据组的效果在Token Masking和Construct Masking上都优于Raw数据，这是由于抽象化保证了较小的词汇量并且简化了预测任务。而在Block Masking上由于整体的预测成功率都较低，所以没法体现优越性。    </p>
<p>​    在大多数情况下，Android数据集上的效果都优于Java，这表明了模型在场景更具体的代码数据上表现更好（因为Android代码中可能有更多固定模式的配置、组件代码）</p>
<p>​        作者还比较了RoBERTa模型和n-gram模型在相同数据集上的表现，数据显示，RoBERTa的Perfect Predictions的效果在各组数据上都优于n-gram。</p>
<p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221116203553596.png" alt="image-20221116203553596"></p>
<p>​    这篇文章主要的工作是对一些市面上已有的模型、工具的组合，并且使用多种统计手段比较测试效果。和一些NLP领域使用BERT模型不同，这篇文章的作者只Mask掉了一个Token或多个结尾处连续的Token(在Token Masking中)，这种手段更符合代码补全的使用场景（程序员敲出一行程序前面一部分的代码，系统自动补全后面的整句代码），并且对Mask的限制可能使得整个模型的复杂度降低，训练出来的模型更拟合真实场景。</p>
<p>​    这篇文章中主要用到的技术包括：</p>
<p>​        <strong>模型</strong>：RoBERTa(Bidirectional Encoder Representations from Transformers)，n-gram </p>
<p>​        <strong>评价指标</strong>：BLEU score，Levenshtein distance(编辑距离)</p>
<p>​        <strong>代码数据处理方法</strong>：Abstract(使用了src2abs库，是抽象Java源代码的工具），BPE(byte pair encoder，字节对编码)</p>
<p>​        <strong>结果统计比较方法</strong>：McNemar’s test ，ORs(Odds Ratios)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/11/16/An%20Empirical%20Study%20on%20the%20Usage%20of%20BERT%20Models%20for%20Code%20Completion/" data-id="clbaeg52w000140txamft71k0" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bert/" rel="tag">Bert</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Code-Completion/" rel="tag">Code Completion</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Flink" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/11/12/Flink/" class="article-date">
  <time datetime="2022-11-12T05:13:51.000Z" itemprop="datePublished">2022-11-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/11/12/Flink/">Flink</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Flink是一个分布式的流处理框架。能够对有界、无界的数据流进行处理。Flink核心是流处理，但也可以通过给数据流设限，从而支持批处理，这与Spark Streaming的处理思想相反。</p>
<h3 id="Flink核心概念"><a href="#Flink核心概念" class="headerlink" title="Flink核心概念"></a>Flink核心概念</h3><h4 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h4><p>流分为有界流和无界流。有界流指的是有固定大小，不随时间增加而增长的数据，比如我们保存在 Hive 中的一个表；而无界流指的是数据随着时间增加而增长，计算状态持续进行，比如我们消费 Kafka 中的消息，消息持续不断，那么计算也会持续进行不会结束。</p>
<h4 id="State"><a href="#State" class="headerlink" title="State"></a>State</h4><p>状态指的是在进行流式计算过程中的信息。一般用作容错恢复和持久化，流式计算在本质上是<strong>增量计算</strong>，也就是说需要不断地查询过去的状态。</p>
<h4 id="Time"><a href="#Time" class="headerlink" title="Time"></a>Time</h4><p>Flink 支持了 Event time、Ingestion time、Processing time 等多种时间语义，时间是我们在进行 Flink 程序开发时判断业务状态是否滞后和延迟的重要依据。</p>
<h4 id="算子链"><a href="#算子链" class="headerlink" title="算子链"></a>算子链</h4><p>在分布式运行环境中，Flink 提出了<strong>算子链</strong>的概念，Flink 将多个算子放在一个任务中，由同一个线程执行，减少线程之间的切换、消息的序列化/反序列化、数据在缓冲区的交换，减少延迟的同时提高整体的吞吐量。</p>
<h3 id="Flink-集群模型和角色"><a href="#Flink-集群模型和角色" class="headerlink" title="Flink 集群模型和角色"></a>Flink 集群模型和角色</h3><h4 id="JobManager"><a href="#JobManager" class="headerlink" title="JobManager"></a>JobManager</h4><p>集群管理者，负责调度任务、协调 checkpoints、协调故障恢复、收集 Job 的状态信息，并管理 Flink 集群中的从节点 TaskManager。</p>
<h4 id="TaskManager"><a href="#TaskManager" class="headerlink" title="TaskManager"></a>TaskManager</h4><p>实际负责执行计算的 Worker，在其上执行 Flink Job 的一组 Task。</p>
<h4 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h4><p>用户在提交编写好的 Flink 工程时，会先创建一个客户端再进行提交，这个客户端就是 Client，Client 会根据用户传入的参数选择使用 yarn per job 模式、stand-alone 模式还是 yarn-session 模式将 Flink 程序提交到集群。</p>
<h3 id="Flink-资源和资源组"><a href="#Flink-资源和资源组" class="headerlink" title="Flink 资源和资源组"></a>Flink 资源和资源组</h3><p>​    在Flink集群中，一个TaskManger就是一个 JVM 进程，并且会用独立的线程来执行 task，为了控制一个 TaskManger 能接受多少个 task，Flink 提出了 Task Slot 的概念。</p>
<p>​    假如一个 TaskManager 拥有 5 个 slot，那么该 TaskManager 的计算资源会被平均分为 5 份，不同的 task 在不同的 slot 中执行，避免资源竞争。但是需要注意的是，slot 仅仅用来做内存的隔离，对 CPU 不起作用。那么运行在同一个 JVM 的 task 可以共享 TCP 连接，减少网络传输，在一定程度上提高了程序的运行效率，降低了资源消耗。</p>
<h3 id="反压-BackPressure"><a href="#反压-BackPressure" class="headerlink" title="反压(BackPressure)"></a>反压(BackPressure)</h3><p>​    反压是分布式处理系统中经常遇到的问题，当消费者速度低于生产者的速度时，则需要消费者将信息反馈给生产者使得生产者的速度能和消费者的速度进行匹配。</p>
<p>​    Flink没有使用任何复杂的机制来解决反压问题，Flink 在数据传输过程中使用了分布式阻塞队列。在一个阻塞队列中，当队列满了以后发送者会被天然阻塞住，这种阻塞功能相当于给这个阻塞队列提供了反压的能力。</p>
<h3 id="DataStream"><a href="#DataStream" class="headerlink" title="DataStream"></a>DataStream</h3><p>​    Flink采用了 DataSet 和 DataStream 两套 API 来适配不同的应用场景(批量计算场景和流式计算场景)。对于DataSet而言，Source部分来源于文件、表或者 Java 集合；而 DataStream的Source部分则一般是消息中间件比如Kafka等。</p>
<p>​    Flink 程序的基础构建模块是<strong>流</strong>（Streams）和<strong>转换</strong>（Transformations），每一个数据流起始于一个或多个 <strong>Source</strong>，并终止于一个或多个 <strong>Sink</strong>。数据流类似于<strong>有向无环图</strong>（DAG）。</p>
<h3 id="故障恢复和重启策略"><a href="#故障恢复和重启策略" class="headerlink" title="故障恢复和重启策略"></a>故障恢复和重启策略</h3><h4 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h4><p>​    Flink 支持了不同级别的故障恢复策略，jobmanager.execution.failover-strategy 的可配置项有两种：full 和 region。</p>
<p>​    当我们配置的故障恢复策略为 full 时，集群中的 Task 发生故障，那么该任务的所有 Task 都会发生重启。而在实际生产环境中，我们的大作业可能有几百个 Task，出现一次异常如果进行整个任务重启，那么经常会导致长时间任务不能正常工作，导致数据延迟。</p>
<p>​    但是事实上，我们可能只是集群中某一个或几个 Task 发生了故障，只需要重启有问题的一部分即可，这就是 Flink <strong>基于 Region 的局部重启策略</strong>。在这个策略下，Flink 会把我们的任务分成不同的 Region，当某一个 Task 发生故障时，Flink 会计算需要故障恢复的最小 Region。</p>
<ul>
<li>发生错误的 Task 所在的 Region 需要重启；</li>
<li>如果当前 Region 的依赖数据出现损坏或者部分丢失，那么生产数据的 Region 也需要重启；</li>
<li>为了保证数据一致性，当前 Region 的下游 Region 也需要重启</li>
</ul>
<h4 id="重启策略"><a href="#重启策略" class="headerlink" title="重启策略"></a>重启策略</h4><p>Flink 提供了多种类型和级别的重启策略，常用的重启策略包括：</p>
<ul>
<li>固定延迟重启策略模式</li>
<li>失败率重启策略模式</li>
<li>无重启策略模式</li>
</ul>
<h3 id="并行度"><a href="#并行度" class="headerlink" title="并行度"></a>并行度</h3><p>​    并行度是 Flink 执行任务的核心概念之一，它被定义为在分布式运行环境中我们的一个算子任务被切分成了多少个子任务并行执行。提高任务的并行度（Parallelism）在很大程度上可以大大提高任务运行速度。</p>
<p>​    一般情况下，我们可以通过四种级别来设置任务的并行度。</p>
<ul>
<li><p>算子级别</p>
<p>在代码中可以调用 setParallelism 方法来设置每一个算子的并行度。</p>
</li>
<li><p>执行环境级别</p>
<p>在创建 Flink 的上下文时可以显示的调用 env.setParallelism() 方法，来设置当前执行环境的并行度，这个配置会对当前任务的所有算子、Source、Sink 生效。</p>
</li>
<li><p>提交任务级别</p>
<p>用户在提交任务时，可以显示的指定 -p 参数来设置任务的并行度。</p>
<p>eg:   ./bin/flink run -p 10 WordCount.jar</p>
</li>
<li><p>系统配置级别</p>
<p>flink-conf.yaml 中的：parallelism.default</p>
</li>
</ul>
<p>整体上讲，这四种级别的配置生效优先级如下：<strong>算子级别 &gt; 执行环境级别 &gt; 提交任务级别 &gt; 系统配置级别</strong>。</p>
<h3 id="窗口和时间"><a href="#窗口和时间" class="headerlink" title="窗口和时间"></a>窗口和时间</h3><p>三种窗口</p>
<ul>
<li><p><strong>滚动窗口</strong>，窗口数据有固定的大小，窗口中的数据不会叠加；    </p>
<p>eg:   .window(TumblingEventTimeWindows.of(Time.seconds(5)))        //tumbling event-time windows</p>
<p>​        .window(TumblingProcessingTimeWindows.of(Time.seconds(5)))     //tumbling processing-time windows</p>
<p>​        .window(TumblingEventTimeWindows.of(Time.hours(1), Time.minutes(15)))    //1 hour tumbling event-time windows offset by 15 minutes.</p>
</li>
<li><p><strong>滑动窗口</strong>，窗口数据有固定的大小，并且有生成间隔；    </p>
<p>eg:     .window(SlidingEventTimeWindows.of(Time.seconds(10), Time.seconds(5)))        //sliding event-time windows</p>
<p>​         .window(SlidingProcessingTimeWindows.of(Time.seconds(10), Time.seconds(5)))    //sliding processing-time windows</p>
<p>​        .window(SlidingProcessingTimeWindows.of(Time.hours(12), Time.hours(1), Time.hours(-8)))    </p>
<p>​                                                                                                                //sliding processing-time windows offset by -8 hours</p>
<p>​        </p>
</li>
<li><p><strong>会话窗口</strong>，窗口数据没有固定的大小，根据用户传入的参数进行划分，窗口数据无叠加。</p>
<p>eg:    </p>
<p>​    .window(EventTimeSessionWindows.withGap(Time.minutes(10)))          //event-time session windows with static gap</p>
<p>​    </p>
</li>
</ul>
<p>三种时间</p>
<ul>
<li><strong>事件时间</strong>（Event Time），即事件实际发生的时间；</li>
<li><strong>摄入时间</strong>（Ingestion Time），事件进入流处理框架的时间；</li>
<li><strong>处理时间</strong>（Processing Time），事件被处理的时间。</li>
</ul>
<h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><h4 id="DataSet-WordCount"><a href="#DataSet-WordCount" class="headerlink" title="DataSet WordCount"></a>DataSet WordCount</h4><p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221112204051668.png" alt="image-20221112204051668"></p>
<p>基于给定的DataSet计算</p>
<h4 id="DataStream-WordCount"><a href="#DataStream-WordCount" class="headerlink" title="DataStream WordCount"></a>DataStream WordCount</h4><p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221112204621342.png" alt="image-20221112204621342"></p>
<p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221112204632804.png" alt="image-20221112204632804"></p>
<p>DataStream部分踩了一些小坑</p>
<p>1、不管是在单机运行（在Ide里的Remote Development窗口中run是单机运行，不会提交任务到集群，只是用了本机的Flink Lib）还是在集群上运行，监听端口要在任务提交前让各个Task Worker都可见。</p>
<p>​    因此在运行任务前，应该运行nc -lk 9527 先打开socket端口</p>
<p>​    另外，在本机运行时，hostname使用”localhost”,”0.0.0.0”都可以；但是在集群上运行时，hostname要是一个所有worker都能监听到的地址，所以应该写成运行nc -lk命令的那台主机的地址(“172.19.240.113”)</p>
<p>2、Flink在1.12.2版本中deprecate了一些方法，如keyBy()方法不支持fieldname了，需要使用选择器(wordWithCount-&gt; wordWithCount.word)。还有timeWindow()方法也被废弃了，Flink的窗口的用法明天再具体看，今天光踩坑了。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/11/12/Flink/" data-id="clbaeg530000340txhy8x3e59" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B5%81%E8%AE%A1%E7%AE%97/" rel="tag">流计算</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Raft-Exntended" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/31/Raft-Exntended/" class="article-date">
  <time datetime="2022-10-31T10:30:19.000Z" itemprop="datePublished">2022-10-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/">技术论文研读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/31/Raft-Exntended/">Raft-Exntended</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>​    Raft是一个管理日志复制的共识算法。它产生的结果等价于Paxos，并且与Paxos效率相同，但是其结构却和Paxos不同，它的结构比Paxos更易理解从而使得基于Raft构建一个实用系统更容易。</p>
<p>​    为了加强可理解性，Raft将共识算法的重要元素，例如leader election，log replication，safety，并且加强了一致性从而降低了需要考虑的状态。Raft也采用了一种新的机制来更换集群成员，其采用了overlapping majority来保证安全性。</p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>​    一致性算法使得一个集群中的机器可以像一个整体一样工作，即使其中的一些机器遭遇了故障也可以正常工作。因此，其在构建可靠的大规模软件系统方面起到了很大的作用。Paxos在过去十年主导着一致性算法的研究。</p>
<p>​    然而，Paxos是很难理解的，并且为了实际的落地，其结构需要做很多复杂的改变。Raft也就因此而生，Raft产生的初衷就是提高可理解性，其中采用了分割技术（Raft分离了leader election，log replication，safety）和状态空间减少（与Paxos相比，Raft减少了不确定性和server与其他server达成一致的方法）。</p>
<p>​    Raft与很多共识算法相似，但它有着如下的几个新颖的特性：</p>
<ul>
<li>Strong leader：Raft 采用了更强的leadership。例如，日志条目只能从leader流向其他servers。这简化了日志复制的管理并且使得Raft更容易理解。</li>
<li>Leader election：Raft 采用了随机时钟来选举leader。这使得解决冲突更加简单快捷。</li>
<li>Membership changes：Raft 通过一种新的joint consensus的方法来实现server集合的改变，其中两个不同配置下的majority在过度阶段会发生重合。这能让集群在配置改变时也能继续正常运行。</li>
</ul>
<h3 id="Replicated-state-machines"><a href="#Replicated-state-machines" class="headerlink" title="Replicated state machines"></a>Replicated state machines</h3><p>​    共识算法是在复制状态机的背景下被提出的。在这个方法中，一组服务器上的状态机计算同一个状态产生多个副本，并且当某些服务器挂掉的时候可以继续操作。复制状态机被用来解决一系列分布式系统中容错的问题。例如，只有单一的集群领导者的大规模系统，如GFS、HDFS、RAMCloud，通常使用一个单独的复制状态机用来管理leader election以及存储集群配置信息来应对leader crashes。复制状态机的例子有Chubby和ZooKeeper。</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221028203531730.png" alt="image-20221028203531730" style="zoom:50%;" />

<p>​    复制状态机的功能通常使用日志复制实现，如图1。每一个server都保存有包含一系列命令的log，其内部的状态机按顺序执行这些命令。每一个log都包含有相同顺序的命令，所以每一个状态机都可以计算得到相同的状态、产生相同顺序的输出。</p>
<p>​    一致性算法的任务就是保证复制日志的一致性。服务器上的一致性模块，接收来自客户端的命令，并追加到日志中。它和其它服务器上的一致性模块进行通信，确保每一个服务器上的日志都包含相同顺序的相同请求。请求命令复制完成后，状态机会按照日志中的命令顺序进行执行。并将结果返回给客户端。由此，这些服务器就构成了统一的，高可靠性的复制状态机。</p>
<p>​    实际系统中的共识算法通常有以下特性：</p>
<ul>
<li>保证非拜占庭条件下的安全，（非拜占庭条件）包括网络延迟、网络分区、丢包、冗余和乱序。</li>
<li>集群中大多数机器能够运行并且能与其他机器和客户端通信时，保证可用性。（5个server挂2个，集群仍可用）</li>
<li>不依赖时间保证一致性，时钟错误和极端情况下的消息延迟最多只会导致可用性问题。</li>
<li>通常情况下，大多数机器完成对一个命令的执行后，就可以认为完成了执行。（少部分慢执行机器不会影响整个系统的性能）</li>
</ul>
<h3 id="What’s-wrong-with-Paxos"><a href="#What’s-wrong-with-Paxos" class="headerlink" title="What’s wrong with Paxos?"></a>What’s wrong with Paxos?</h3><p>两个缺点：太难懂&amp;没有为实现提供好的基础</p>
<h3 id="Design-for-understandability"><a href="#Design-for-understandability" class="headerlink" title="Design for understandability"></a>Design for understandability</h3><p>Raft采用了问题分解（分解了leader election, log replication, safety和membership changes）和减少需要考虑的状态数来使得整个算法更容易理解。</p>
<h3 id="The-Raft-consensus-algorithm"><a href="#The-Raft-consensus-algorithm" class="headerlink" title="The Raft consensus algorithm"></a>The Raft consensus algorithm</h3><p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221029113343983.png" alt="image-20221029113343983"></p>
<p>Figure2简要描述了Raft算法</p>
<p><u><strong>State</strong></u>：</p>
<p><strong>Persistent state on all servers</strong>（响应RPC之前更新）：</p>
<p>currentTerm: server最后看到的term号(服务启动时，初始化为0，单调递增)</p>
<p>votedFor：当前term内投票给的候选人Id</p>
<p>log[]：日志条目，每个条目包含状态机要执行的命令和此条目从leader处获得时的term号</p>
<p><strong>Volatile State on all servers</strong>：</p>
<p>commitIndex：已知的被提交的最大日志条目的索引值（初始为0，单调递增）</p>
<p>lastApplied：被状态机执行的最大日志条目的索引值（初始为0，单调递增）</p>
<p><strong>Volatile State on leaders</strong>（每次选举过后重新初始化）：</p>
<p>nextIndex[]：要发送给每个服务器的下一个日志条目的索引（初始化为leader的上一条日志的索引值+1）</p>
<p>matchIndex[]：已经复制到每个服务器的最大索引值(初始化为0，单调递增)</p>
<p><u><strong>AppendEntries RPC</strong></u>（由leader发起的日志复制，同时也用作心跳检测）</p>
<p><strong>Arguments</strong>：</p>
<p>term: leader的term</p>
<p>leaderId： leader的id，使得其他followers可以重定向客户端到leader</p>
<p>prevLogIndex：当前日志之前的日志索引</p>
<p>prevLogTerm：当前日志之前的日志的leader Term</p>
<p>entries[]：将要存储的日志条目（心跳检测时为空，可能同时发一条或多条来提高效率）</p>
<p>leaderCommit：leader提交的日志条目索引值</p>
<p><strong>Results</strong>：</p>
<p>term：当前的term，leader更新自己的term</p>
<p>success：如果follower服务器能匹配上prevLogIndex和prevLogTerm时，返回true</p>
<p><strong>Receiver implementation</strong>：</p>
<p>1.如果term小于server的currentTerm，则返回false</p>
<p>2.如果日志中没有一个索引为prevLogIndex的条目的term与prevLogTerm相匹配，则返回false</p>
<p>3.如果已经存在的日志条目与新的日志条目冲突(index相同但是term不同)，删除此日志条目及此条目之后的条目。</p>
<p>4.添加当前log不存在的新条目</p>
<p>5.如果leaderCommit&gt;commitIndex，将commitIndex设置成leaderCommit和最新的日志条目的Index中较小的一个</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221029113524417.png" alt="image-20221029113524417" style="zoom:67%;" />

<p>Figure3描述了Raft算法的一些重要属性</p>
<p><strong>Election Safety</strong>：一个任期内只能有一个leader当选</p>
<p><strong>Leader Append-Only</strong>：一个leader不会覆盖或删除自己的日志条目，只会追加新条目</p>
<p><strong>Log Matching</strong>：如果两个日志包含一个index和term都相同的条目，则两个日志在这个index之前的条目都相同</p>
<p><strong>Leader Completeness</strong>：如果一个日志条目在一个term中被提交了，则这个条目在以后term的leader中仍被保存</p>
<p><strong>State Machine Safety</strong>：当一个server在其状态机上执行了一个日志条目，其他机器不会在相同index下执行不同的日志条目。</p>
<h4 id="Raft-basics"><a href="#Raft-basics" class="headerlink" title="Raft basics"></a>Raft basics</h4><p>​    Raft集群中的server会处于三种状态之一：leader，follower，candidate。正常情况下，集群中有一个leader，其他的都是follower。</p>
<ul>
<li>follower是被动的：他们只简单响应来自leader和candidate的请求。</li>
<li>leader会处理所有来自客户端的请求（如果客户端请求一个follower，follower会将该请求重定向到leader）。</li>
<li>Candidate状态是选举新leader的。</li>
</ul>
<p>三种状态的转换如Figure4</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221029165302536.png" alt="image-20221029165302536" style="zoom:67%;" />

<p>​    Raft将时间划分为长度不同的term。每一个term以leader election开始，竞争成功的candidate转换成leader，负责term内的管理。在一些特殊情况下，选举产生分歧，这一个term就会以没有leader而结束。一个新的term就会马上开始。</p>
<p>​    Term相当于Raft中的一个逻辑时钟，每一次server间的通信都会交换彼此的term信息，如果一个server的term比其它服务器的小，它就会更新自己的term到较大的term。如果这个过期的server是leader或candidate，则它们会转换自己为follower。如果一个follower接收到一个过期term的请求，它会拒绝掉此请求。</p>
<p>​    Raft的server间通过RPC通信，基础的共识算法只需要使用到RequestVote RPC（选举时使用）和Append Entries RPCs（日志复制及心跳检测使用）。服务器收不到响应时会重发RPC，并且服务器采用并行机制发送RPC。</p>
<h4 id="Leader-election"><a href="#Leader-election" class="headerlink" title="Leader election"></a>Leader election</h4><p>​    一个server刚启动时，是follower状态，并且一直保持这种状态只要从leader或candidate接收到合法的RPC请求。Leader会定期发送心跳给所有的followers。如果一个follower在一定时间内没有接收到来自leader的消息，则判定leader下线并开始下一轮选举。</p>
<p>​    开始选举时，一个follower会增加它的currentTerm并将状态切换为Candidate。然后标识votedFor为自己，并且发送RequestVote RPCs给集群中的其他服务器。Candidate会保持这种状态直到以下三种情况中的一种发生：</p>
<ul>
<li>赢得选举，成为leader</li>
<li>其他的server赢得选举</li>
<li>选举超时，没有选出leader</li>
</ul>
<p>​    当一个candidate在一个term中赢得集群中大多数机器(超过一半，此原则保证了一个term内最多出现一个candidate)的选票时，就赢得了选举。投票采用先到先服务的策略，先请求的candidate会获得该server的投票。candidate赢得选举成为leader后，会立即发送心跳消息到其他server，组织新一轮的leader election。</p>
<p>​    当candidate在等待投票结果时，可能会收到一个来自新leader的带有更新term号的AppendEntries RPC。如果这个term号大于等于candidate的term，则此candidate认可此结果，并转换为follower。如果RPC中的term小于candidate的term，则candidate拒绝此RPC，并保持candidate状态。</p>
<p>​    如果同一时间，过多的follower成为candidate，分走了票数，没有一个candidate获得了大多数的投票。则candidate进入超时状态并进入新一轮的选举。Raft采用随机的选举超时时间来确保这种情况很少发生并且能很快解决。Raft将选举超时设定为150~300ms之间的一个随机时间。这样当所有candidate都没法获得大多数投票时，会在不同的超时时间后进入下一轮选举，从而首先进入下一轮（超时时间短）的candidate会很可能赢得下一轮选举，大大减少了下一轮中split votes现象的发生。</p>
<h4 id="Log-replication"><a href="#Log-replication" class="headerlink" title="Log replication"></a>Log replication</h4><p>​    Leader接收到客户端的请求后，会首先将命令追加到自己的log中作为一个新条目，接着发送AppendEntries RPC给其他server去复制该条目。当该日志条目安全地复制到了其他的server上(过半)时，leader自身的状态机开始执行这一命令，并将结果返回给客户端。如果有followers宕机或者运行缓慢或者丢包，leader会一直重新发送AppendEntries RPC(即使其已经回复了客户端)，直到所有的followers都存储该条目。</p>
<p>​    <img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221029185522502.png" alt="image-20221029185522502" style="zoom:50%;" /></p>
<p>​    日志的存储组织方式如Figure6。每一个日志条目都保存着一个状态机命令和一个term，term主要用来发现不一致和保证Figure3中的一些属性。每一个日志条目也有一个index来标识其在log中的位置。</p>
<p>​    当一个日志条目被大多数server成功复制时，它就会被leader commit，Raft协议保证了所有commited的日志条目都是持久的，并且都会最终被集群中所有的状态机执行。commit一个日志条目时，也会将其前面的所有日志条目一起commit(没有被commit过的)，包括了之前term的leader创建的条目。leader会一直跟踪它最新commit的index，并且在之后的AppendeEntries RPC中都包括此index（包括心跳），以使得其他的follower都可以识别，并将被commit的日志条目应用到自身的状态机中。</p>
<p>​    Raft确保了以下的两个特性（共同组成了Figure3中的Log Matching property）：</p>
<ul>
<li>如果两个日志中的日志条目的term和index都相同，则他们存储的command也相同</li>
<li>如果两个日志中的日志条目的term和index都相同，则之前的所有条目也都相同</li>
</ul>
<p>​    第二个特性，是通过leader在发送AppendEntries RPC中携带其要发送的最新条目之前的preLogIndex和preLogTerm，follower如果没有在它的日志中找到对应的条目具有相同的index和term，那么它就会拒绝这个条目。由每一步条件保证的递推来保证此性质。</p>
<p>​    正常情况下，leader和follower中的日志能保持一致。但是当leader宕机时，就会引发日志的不一致（旧的leader可能有一部分日志还没有成功复制到follower）。follower可能与新的leader的日志不同（可能含有leader没有的条目，也可能缺少leader已有的条目，或者两者都有）。</p>
<p>​    Raft协议中，leader通过强制follower复制自己的日志来保证一致性。leader首先找到能和follower中达成一致的最近的一个日志条目index，然后删除follower在这个日志条目之后的所有所有条目，并且将leader中此条目之后的日志都发送给follower存储。这些操作都由AppendEntries的一致性检查实现。Leader给每个follower维护了nextIndex（下一个将要发送给follower的日志条目的索引）。Leader初始化时，会将所有follower的nextIndex都设置为自己的最新的日志条目的下一个index(latest Index+1)。如果follower的日志不一致，下一个AppendEntries RPCs会返回失败，一次失败后，leader会将该follower的nextIndex减一，一直到找到一致的nextIndex值。然后完成日志同步。</p>
<p>​    如果可以的话，协议还可以减少AppendEntries RPC的次数来优化。比如拒绝RPC时，follower可以将冲突的条目的term和此term内存储的第一个条目返回给leader。这样可以直接将nextIndex跳过那个term中所有的冲突条目。但这样做可能是没有必要的，因为这种不一致性错误并不是经常发生。</p>
<h3 id="Safety"><a href="#Safety" class="headerlink" title="Safety"></a>Safety</h3><p>​    之前Leader Election和Log Replication两节，描述了Raft算法进行领导选举和日志复制的机制。但这些机制并不能有效地保证每个状态机以相同顺序执行相同地命令。例如，一个follower离线期间，leader commit 了一些日志条目，follower恢复后，被选举为leader，然后它用它的新的日志条目覆盖了之前leader commit了的日志条目。不同的server就执行了不同的命令序列。</p>
<p>​    这一节对可被选为leader的server加了一些限制，这些限制确保了每一个term内的leader都能包含之前任一term内leader commit了的日志条目。</p>
<h4 id="Election-restriction"><a href="#Election-restriction" class="headerlink" title="Election restriction"></a>Election restriction</h4><p>​    在所有leader-based的一致性算法中，leader最终都必须保存有所有的已提交的日志条目。Raft使用了一种简单的方法保证了之前所有term中commited的日志条目会在每一个新的leader被选举上时就存在，而不需要传输这些条目给新leader。这意味着，这些日志条目只会从leader流向follower，leader永远不会覆盖已有的日志条目。</p>
<p>​    Raft通过阻止一个没有包含所有commited的日志条目的candidate赢得选举。选举期间，candidate需要与大多数服务器通信，这意味着每一个已经被commited的日志条目一定会出现在这些服务器中至少一个上。当一个candidate的日志比这大多数服务器中的任意一个服务器都更新或同样新时（up-to-date），这就意味着它包含了所有commited的日志条目。RequestVote RPC实现了这种限制：RPC中包含了candidate的log信息，如果投票服务器的日志条目比这个candidate的更新，则其会拒绝这个投票。</p>
<p>​    Raft通过比较两个服务器上最后一个日志条目的term和index来决定谁更up-to-date。如果term不同，则term大的日志新。如果term相同，则index大的日志新。</p>
<h4 id="Committing-entries-from-previous-terms"><a href="#Committing-entries-from-previous-terms" class="headerlink" title="Committing entries from previous terms"></a>Committing entries from previous terms</h4><p>leader知道term内的日志条目一旦被大多数server存储了，就commit了。如果一个leader在commit一个条目前就宕机了，未来的leader会继续尝试完成这个条目的复制。然而一个新的leader不能马上识别出一个在大多数server上都存储了的日志条目。Figure8表现了一种场景，存在大多数server上的日志条目被新的leader覆盖了。</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221031151011593.png" alt="image-20221031151011593" style="zoom:67%;" />

<p>​    为了消除Figure8中的问题，Raft从不通过计算日志条目拷贝到的server数来决定之前的term中的某一个条目是否应该被提交。只有当前term中的日志条目通过这种计数的方式来决定提交；一旦当前term中的一个日志条目通过这种方式被提交了，根据Log Matching原则，它所有之前的日志条目也间接地提交了。也存在有一些情形，leader可以安全地识别一个旧的日志条目被提交了（例如，如果这个条目存储在了所有的server上），但是Raft为了简单使用了更保守的方案。</p>
<p>​    </p>
<h4 id="Follower-and-candidate-crashes"><a href="#Follower-and-candidate-crashes" class="headerlink" title="Follower and candidate crashes"></a>Follower and candidate crashes</h4><p>​    到目前为止，我们都在关注leader的失败。follower和candidate的失败更容易处理，都以相同的方式处理。如果follower或candidate挂掉，则接下来发送给它的RequestVote和AppendEntries RPC都会失败。Raft通过无限次的重试来处理这种状况；当挂掉的服务器重新有效时，RPC请求会完成。如果一个server在完成RPC请求之后回复RPC请求之前挂掉，那么当它恢复时，会再次收到相同的RPC请求。Raft的RPC是幂等的，所以这样不会造成危害。例如，当一个follower接收到AppendEntries请求包含自己已经存在的日志条目时，它会忽视此请求。</p>
<h4 id="Timing-and-availability"><a href="#Timing-and-availability" class="headerlink" title="Timing and availability"></a>Timing and availability</h4><p>​    Raft的需求之一就是安全性不依赖于时间因素：系统不会因为一些事情发生的比预期快或者慢而产生错误的结果。然而，系统的可用性不可避免地受到时间因素的影响。例如，因为server崩溃而造成信息交换时间太长，使得candidate不能在选举超时时间内赢得选举；如果没有一个稳定的leader，Raft不能正常工作。</p>
<p>​    leader选举受时间因素影响较大，当系统满足broadcastTime&lt;&lt;electionTimeout&lt;&lt;MTBF时，Raft才能维持一个稳定的leader。MTBF代表单个服务器的故障发生间隔。</p>
<h3 id="Cluster-membership-changes-此部分lab中不涉及，仅了解"><a href="#Cluster-membership-changes-此部分lab中不涉及，仅了解" class="headerlink" title="Cluster membership changes(此部分lab中不涉及，仅了解)"></a>Cluster membership changes(此部分lab中不涉及，仅了解)</h3><p>​    到目前为止，我们都假定集群配置是固定的。但是在现实中，需要做一些相应的变动。为了避免服务下线，Raft实现了配置变更的自动化，并将其融合进一致性算法中。</p>
<p>​    为了保障配置变更机制的安全，在配置转换期间，不能存在同一任期内选举出现两个leader的现象。不幸的是，没有任何方法能够使得集群能够安全的实现配置转换。自动地转换全部的服务器是不可能的，所有集群在转换期间极有可能出现脑裂现象。</p>
<p>​    <img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221031202022716.png" alt="image-20221031202022716" style="zoom:66%;" /></p>
<p>​    为了确保安全，配置变更必须采用两阶段法。Raft中，集群首先切换到过渡配置状态，我们称之为 joint consensus ，一旦 joint consensus 被提交，系统切换到新的配置状态。joint consensus既包括旧的配置，也包括新的配置：</p>
<ul>
<li>日志条目在集群中被复制到两种配置下所有的服务器。</li>
<li>新旧配置中的服务器都有可能选举成为leader</li>
<li>关于选举和日志条目的提交的协定同时需要新旧配置中的大多数服务器的同意。</li>
</ul>
<p>​    joint consensus允许单个服务器在不影响安全性的基础上，在不同的特定时刻进行不同配置的转换。此外， joint consensus允许集群在配置转换期间继续处理客户端的请求。</p>
<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20221031202731591.png" alt="image-20221031202731591" style="zoom:50%;" />

<p>​    集群配置是通过特殊的日志条目通过日志复制进行存储和传输通讯的，Figure11展示了配置的转换过程。当leader收到配置从 Cold 到 Cnew变更的的请求时，它首先将配置作为日志条目存储为 Cold,new 并复制到其它服务器，一旦某个服务器将收到的 Cold,new 配置日志条目添加到自身的日志，那么之后其所有的决策都将以此配置 Cold,new 为依据（服务器总是以日志中最新的配置为依据进行决策，无论配置条目是否已提交）。这就意味着，leader将使用 Cold,new 配置，来决定配置条目 Cold,new 什么时候提交。当leader宕机时，新的leader将在旧配置 Cold或者联合配置 Cold,new 的机器中选举出来。这取决于获得选举的candidate是否已经收到联合配置 Cold,new 。任何情况下，具有新配置 Cnew 的服务器在这段时间内都不能做出单方面的决定。</p>
<p>​    一旦 Cold,new被提交后，具有Cold或者Cnew的服务器将不能在没有其它服务器允许的情况下做出任何决策， Leader Completeness Property确保了只有具有Cold,new的服务器才能当选为leader。此时，leader将能够安全的创建Cnew的配置条目并将其复制到集群其它服务器。同样，当复制的服务器收到配置条目后就开始使用它。当新的配置被提交后，拥有旧配置的服务器将可以被关闭。</p>
<p>​    在配置转换期间存在着三方面的问题，第一个就是新的服务器初始化启动的时候不包含任何日志条目，当他们加入集群中时，需要花费相当的时间同步到最新的状态，在此期间，它将不能提交任何日志条目。为了避免可用性断层，Raft设定新加入进群的服务器状态为none-voting（leader向他们复制日志，但是不将他们纳入大多数范围）。当新的服务器同步到最新的状态后，就可以执行正常的配置转换过程了。</p>
<p>​    第二个问题是集群leader处在旧的配置中，这种情况下，leader在将Cnew类目提交后就降级转换为follower状态。这就意味着在leader提交配置类目的这段时间了，它在管理着一个不包括自己的集群。它复制日志条目，但是却将自身排除在被集群外。leader的身份状态转换发生在Cnew条目提交的时候，这也是新的配置第一次能够独立决策执行的时刻。在此之前，只有处于Cold的服务器才可以被选举为leader。</p>
<p>​    第三个问题是，无关的服务器（处在Cold的服务器）会扰乱集群运行。因为这些服务器不会收到心跳请求，所以他们就会产生超时并启动新一轮的选举。他们发送的Request Vote RPCs包含了新的任期号，这就会导致当前的leader接收到请求后转换为follower状态，并最终在Cold下的某个服务器当选为新的leader。但是那些无关的的服务器会无限次的不断产生超时，启动选举，最终到会系统可用性的大大降低。</p>
<p>​    为了避免这样的问题，服务器设定当明确认定当前leader存在的情况下，会选择忽略此类的RequestVote RPCs。特别的，当服务器在当前最小选举超时时间内收到一个 RequestVote RPC，它不会更新当前的任期号或者投出选票。这不会影响正常的选举，每个服务器在开始一次选举之前，至少等待一个最小选举超时时间。然而，这有利于避免无关服务器的扰乱：如果leader能够发送心跳给集群，那么它就不会被更大的任期号废除。</p>
<h3 id="Log-Compaction"><a href="#Log-Compaction" class="headerlink" title="Log Compaction"></a>Log Compaction</h3><p>​    Raft日志会伴随着系统的日常运行持续增长。实际应用中，我们不能让它无限制的增长下去。日志越长，占用的存储空间越多，也将耗费状态机更多时间去重新应用日志条目。我们需要适当的机制来处理掉日志中的过期的信息，避免其影响系统的可用性。</p>
<p>​    快照是压缩的最简单的方式，通过快照将某一时刻系统的当前状态写入快照文件，保存到磁盘，然后将这一时刻之前的所有日志丢弃。例如chubby，zookeeper的快照机制。</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221031205002237.png" alt="image-20221031205002237" style="zoom:50%;" />



<p>​    Figure12展示了快照的基本思想。各个服务器独立的对已提交的日志条目进行日志快照。主要的工作是由状态机将它当前的状态写入快照文件。Raft也保留了一些元数据在快照中，例如，last included index：状态机最后应用的日志条目索引，last included term：这一条目的任期。为了支持集群配置变更，快照文件也在last included index之前包含了最新的配置条目。一旦某个服务器完成快照写入，他就会将last include index之前的所有日志条目都删除掉。</p>
<p>​    虽然，正常情况下，各个服务器各自完成各自的快照。但是，偶尔也需要leader向落后的follower发送自身的快照。这一情况通常发生在leader丢弃掉了需要发送到follower的日志条目的时候。当然，这种情况很少发生。和leader保持同步的follower拥有leader的所有日志，但是，落后比较大的follower或者刚加入集群的服务器却并非如此。处理此类follower的机制就是leader发送日志快照来进行同步。</p>
<p>​    <img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221031210055311.png" alt="image-20221031210055311" style="zoom:67%;" /></p>
<p>​    leader使用一种新的RPC请求：InstallSnapshot来向落后的follower发送快照。(Figure13)。当follower接收到此类请求时，需要判断怎么对其进行处理。通常来说，快照包含最新的日志条目（包含接收者不存在的日志条目），这样接收服务器就可以丢弃自身所有的日志条目（可能包含未提交的和与快照中有冲突的条目），然后替换为快照中的日志条目。相反，如果接收者收到的快照包含的日志条目是其自身日志之前部分的条目（因为重传或者其它错误），那么就会将快照覆盖的自身日志条目删除掉，但是这之后的日志条目仍然有效，需要保留下来。</p>
<p>​    follower自行处理快照，违背了Raft的强领导准则。然而，这是事出有因的，leader是为了处理达到一致性状态过程中的冲突的，但是，在进行快照的时候，就已经达成一致性的目的了。数据仍然是从leader流向follower，只是follower可以重新整理他们自己的数据。</p>
<p>​    让我们来思考另外一种leader-based的一致性算法。只有leader可以创建快照，然后发送到follower。这种方式有两个缺点，首先是发送快照造成的带宽浪费，及整个快照进程的拖慢。每个服务器都已经包含了创建快照的数据，因此本地化的快照创建成本更低。其次是，leader的实现会变得更加复杂，例如，leader发送快照的时候，同时需要并行发送新的日志条目，并且不能阻塞客户端请求。</p>
<p>​    另外有两个影响快照性能的论题。</p>
<p>​    第一个，server必须确定什么时候进行快照。如果一个server频繁进行快照，会浪费磁盘带宽和能量；如果太久才快照，这会导致存储空间浪费，并且会增大重启时用来重执行日志的时间。一个简单的实现是在log到达一个固定的大小时进行快照。</p>
<p>​    第二个，创建快照会耗费一定的时间，为了避免影响正常的系统运行，我们可以采用copy-on-write机制，这样新的请求，日志条目的更新不会影响快照的创建。例如，基于功能性结构数据的状态机就天然的支持这种特性。或者我们可以使用操作系统的copy-on-write机制来创建状态机的in-memory快照(Raft的实现采用了这种方法)。</p>
<h3 id="Client-Interaction-与lab实现无关，仅了解"><a href="#Client-Interaction-与lab实现无关，仅了解" class="headerlink" title="Client Interaction(与lab实现无关，仅了解)"></a>Client Interaction(与lab实现无关，仅了解)</h3><p>​    这一章介绍了客户端和Raft的交互，包括客户端如何识别集群leader，以及Raft是如何支持线性化。这些问题是所有一致性算法的共性问题，Raft的实现也大体相同。</p>
<p>​    集群leader负责处理客户端所有的请求。客户端启动时，它随机的连接集群中的一台服务器。如果连接的服务器不是leader，服务器会拒绝客户端的连接，并提供集群最新leader的信息（AppendEntries请求包含leader的网络地址信息）。如果leader宕机，客户端的请求就会超时，需要重新向集群尝试连接。</p>
<p>​    Raft的目标是实现线性化（每一次操作都是即刻执行的，并且只执行一次），然而，就像前面描述的，Raft也存在可能会多次执行同一个命令的情景：例如，leader 在提交完日志条目后及回复客户端之前宕机，客户端就会重新向新的leader发起同样的命令请求。这将会导致同一命令被再次执行。解决方案是，客户端给每一次的请求命令添加一个唯一的序列码，这样服务器状态机就可以根据请求的序列码追踪相应的回复。当服务器收到一个和之前序列码相同的命令请求时，服务器就可以不必重新执行命令，而获取响应返回给客户端。</p>
<p>​    只读操作可以直接处理而不需要写入日志，但是可能会返回过期数据，因为响应的leader可能已经被新的leader所替代。线性特性不允许返回过期数据，Raft在不记录日志的情况下需要两个额外的预防措施来避免这一情况的发生。第一，leader必须拥有最新的日志条目。 Leader Completeness Property能够保证leader拥有所有已提交的日志条目。但是在任期之初，leader并不知道那些条目是所有已提交的条目。为了解决这个问题，在任期开始的时候，leader需要提交一个空的 no-op条目。第二，leader在处理只读请求之前必须先检测一下自己是否已经被替代。Raft通过让leader在处理只读请求之前向集群大多数服务器发送心跳信息来完成检测。领导人可以依赖心跳机制来实现一种租约的机制，但是这种方法依赖时序来保证安全性。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/31/Raft-Exntended/" data-id="clbaeg53a000i40txelu6fbep" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Raft/" rel="tag">Raft</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-RocketMQ" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/27/RocketMQ/" class="article-date">
  <time datetime="2022-10-27T08:28:31.000Z" itemprop="datePublished">2022-10-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/27/RocketMQ/">RocketMQ</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="SpringBoot-RocketMQ整合流程"><a href="#SpringBoot-RocketMQ整合流程" class="headerlink" title="SpringBoot+RocketMQ整合流程"></a>SpringBoot+RocketMQ整合流程</h2><h3 id="安装RocketMQ-Windows下"><a href="#安装RocketMQ-Windows下" class="headerlink" title="安装RocketMQ(Windows下)"></a>安装RocketMQ(Windows下)</h3><h4 id="下载RocketMQ压缩包"><a href="#下载RocketMQ压缩包" class="headerlink" title="下载RocketMQ压缩包"></a>下载RocketMQ压缩包</h4><p><a target="_blank" rel="noopener" href="https://archive.apache.org/dist/rocketmq/4.9.4/rocketmq-all-4.9.4-bin-release.zip">https://archive.apache.org/dist/rocketmq/4.9.4/rocketmq-all-4.9.4-bin-release.zip</a></p>
<p>下载后解压到一个不包含空格的目录下</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221027204613444.png" alt="image-20221027204613444" style="zoom:67%;" />



<h4 id="配置环境变量中的系统变量"><a href="#配置环境变量中的系统变量" class="headerlink" title="配置环境变量中的系统变量"></a>配置环境变量中的系统变量</h4><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221027205011948.png" alt="image-20221027205011948" style="zoom:67%;" />



<h4 id="启动nameserver和broker"><a href="#启动nameserver和broker" class="headerlink" title="启动nameserver和broker"></a>启动nameserver和broker</h4><p>cd到C:\rocketmq\bin目录下</p>
<p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221027205051594.png" alt="image-20221027205051594"></p>
<p>执行 mqnamesrc.cmd，启动nameserver</p>
<p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221027205129222.png" alt="image-20221027205129222"></p>
<p>执行mqbroker.cmd -n localhost:9876，启动broker</p>
<h3 id="使用Rocket-Dashboard"><a href="#使用Rocket-Dashboard" class="headerlink" title="使用Rocket Dashboard"></a>使用Rocket Dashboard</h3><p>使用Docker运行</p>
<h4 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a>拉取镜像</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull apacherocketmq/rocketmq-dashboard:latest</span><br></pre></td></tr></table></figure>



<h4 id="运行容器"><a href="#运行容器" class="headerlink" title="运行容器"></a>运行容器</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name rocketmq-dashboard -e &quot;JAVA_OPTS=-Drocketmq.namesrv.addr=172.19.144.64:9876&quot; -p 8080:8080 -t apacherocketmq/rocketmq-dashboard:latest</span><br></pre></td></tr></table></figure>

<p>JAVA_OPTS=-Drocketmq.namesrv.addr=(无线局域网适配器 WLAN:IPV4地址)</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221027214242077.png" alt="image-20221027214242077" style="zoom:67%;" />



<h3 id="在SpringBoot中集成"><a href="#在SpringBoot中集成" class="headerlink" title="在SpringBoot中集成"></a>在SpringBoot中集成</h3><h4 id="添加依赖"><a href="#添加依赖" class="headerlink" title="添加依赖"></a>添加依赖</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--        rocketMQ依赖--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.rocketmq<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>rocketmq-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.2.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h4 id="修改配置项-application-yml"><a href="#修改配置项-application-yml" class="headerlink" title="修改配置项(application.yml)"></a>修改配置项(application.yml)</h4><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221027214447789.png" alt="image-20221027214447789" style="zoom:67%;" />

<h4 id="在Rocket-Dashboard中创建Topic"><a href="#在Rocket-Dashboard中创建Topic" class="headerlink" title="在Rocket Dashboard中创建Topic"></a>在Rocket Dashboard中创建Topic</h4><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221027214727826.png" alt="image-20221027214727826" style="zoom:50%;" />



<h4 id="创建消费者"><a href="#创建消费者" class="headerlink" title="创建消费者"></a>创建消费者</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@RocketMQMessageListener(topic = &quot;operation-topic&quot;,consumerGroup = &quot;consumer-group&quot;,messageModel = MessageModel.CLUSTERING,</span></span><br><span class="line"><span class="meta">consumeMode = ConsumeMode.ORDERLY)</span></span><br><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MqTestListener</span> <span class="keyword">implements</span> <span class="title">RocketMQListener</span>&lt;<span class="title">String</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onMessage</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;接收到消息:&#123;&#125;&quot;</span>,s);</span><br><span class="line">        System.out.println(<span class="string">&quot;消息:&quot;</span>+s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="使用Test方法发送消息"><a href="#使用Test方法发送消息" class="headerlink" title="使用Test方法发送消息"></a>使用Test方法发送消息</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MqTest</span> <span class="keyword">extends</span> <span class="title">SpringBootTicketApplicationTests</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    RocketMQTemplate rocketMQTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendHello</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        SendResult result=rocketMQTemplate.syncSend(<span class="string">&quot;operation-topic&quot;</span>,<span class="string">&quot;hello,world&quot;</span>);</span><br><span class="line">        log.info(<span class="string">&quot;发送结果:&#123;&#125;&quot;</span>, JSON.toJSONString(result));</span><br><span class="line">        Thread.sleep(<span class="number">60000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>因为发送消息后要等待消费者消费消息再关闭整个Spring进程，所以要sleep一下。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/27/RocketMQ/" data-id="clbaeg53c000p40txdnfad26o" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/RocketMQ/" rel="tag">RocketMQ</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SpringBoot/" rel="tag">SpringBoot</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" rel="tag">消息队列</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-身份认证方案" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/24/%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81%E6%96%B9%E6%A1%88/" class="article-date">
  <time datetime="2022-10-24T05:27:07.000Z" itemprop="datePublished">2022-10-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/">技术基础</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/24/%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81%E6%96%B9%E6%A1%88/">身份认证方案</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>对于服务端渲染：推荐使用Session认证；而对于前后端分离的项目：推荐使用JWT</p>
<h3 id="Session认证"><a href="#Session认证" class="headerlink" title="Session认证"></a>Session认证</h3><p>由于HTTP协议是无状态的，所以为了使得不需要每次请求都要用户重新认证，我们一般将一些用户认证信息保存在浏览器的Cookie中。客户端重新发起请求时，会自动将当前域名下所有的未过期Cookie一同发送给服务端。</p>
<p>Cookie是存储在浏览器中，浏览器可以读写Cookie，因此不应将敏感的隐私数据存在Cookie中。</p>
<p>Session的工作原理如下：</p>
<ol>
<li>浏览器第一次发送请求到服务端，服务端认证通过以后，在缓存(一般采用Redis)中创建一个Session，同时在请求头中设置Cookie(name为JSESSIONID,value为sessionID)，浏览器会根据请求头保存该Cookie</li>
<li>浏览器再次请求服务端时，会携带该Cookie，服务端根据cookie中的sessionID去缓存中查找对应的Session，完成认证</li>
</ol>
<p>Session认证的局限性：需要配合Cookie使用，Cookie默认不支持跨域，前端跨域请求后端接口时，需要做额外的很多配置。所以前端需要跨域请求后端接口时，推荐使用JWT认证机制。</p>
<h3 id="JWT认证"><a href="#JWT认证" class="headerlink" title="JWT认证"></a>JWT认证</h3><p>Json Web Token，是目前最流行的跨域认证解决方案。</p>
<p>工作原理如下：</p>
<ol>
<li>客户端第一次发送请求给服务端，服务端验证用户的账号与密码通过后，将用户的信息对象，经过加密后生成Token字符串，并将Token保存在localStorage或SessionStorage上。</li>
<li>客户端再次发送请求时，通过请求头的Authorization字段，将Token发送给服务器。服务器将Token字符串还原成用户信息对象，完成认证。</li>
</ol>
<p>JWT的组成部分：Header(头部)，Payload(有效载荷)，Signature(签名)。三者之间使用”.”分割。Header和Signature是安全性相关部分，Payload部分存储的是用户信息经过加密之后生成的字符串。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/24/%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81%E6%96%B9%E6%A1%88/" data-id="clbaeg53u002v40tx3m891p8i" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AE%89%E5%85%A8/" rel="tag">安全</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Redis" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/21/Redis/" class="article-date">
  <time datetime="2022-10-21T05:18:37.000Z" itemprop="datePublished">2022-10-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/">技术基础</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/21/Redis/">Redis</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="redis的数据结构"><a href="#redis的数据结构" class="headerlink" title="redis的数据结构"></a>redis的数据结构</h3><p>5种基本类型：String、Hash、List、Set、SortedSet</p>
<p>HyperLogLog：用于基数统计，计算一个数据集中不重复元素的个数。</p>
<p>Geo：用于存放地理位置（经纬度）</p>
<p>Pub/Sub：消息通信模式，Pub发布消息，Sub接收消息。</p>
<h3 id="Redis的keys指令"><a href="#Redis的keys指令" class="headerlink" title="Redis的keys指令"></a>Redis的keys指令</h3><p>可以使用keys指令来在大量的kv对中寻找特定模式的key集合。</p>
<p>但是由于Redis是单线程的，keys指令会阻塞线程，线上服务会停顿，此时应该使用scan指令。</p>
<h3 id="Redis的数据持久化"><a href="#Redis的数据持久化" class="headerlink" title="Redis的数据持久化"></a>Redis的数据持久化</h3><p>Redis提供了两种持久化方式，RDB(Redis DataBase)和AOF(Append Only File)。</p>
<p>RDB：在不同的时间点，将Redis存储的数据生成快照并存储到磁盘上。</p>
<p>AOF：将Redis执行过的所有写指令记录下来，在下次Redis重新启动时，把这些写指令从头执行一次，就可以实现数据恢复了。</p>
<p>两种方法也可以同时使用，Redis重启时，会先使用RDB持久化文件重新构建内存，再根据AOF来恢复到重启前的状态。</p>
<h3 id="RDB的原理"><a href="#RDB的原理" class="headerlink" title="RDB的原理"></a>RDB的原理</h3><p>Fork&amp;Copy on write</p>
<p>Redis会创建(fork)一个子进程来进行RDB操作；子进程创建后，父子进程共享内存数据段，父进程继续提供读写服务，写脏的数据会逐渐和子进程分离开来。</p>
<h3 id="Redis缓存雪崩、缓存击穿、缓存穿透"><a href="#Redis缓存雪崩、缓存击穿、缓存穿透" class="headerlink" title="Redis缓存雪崩、缓存击穿、缓存穿透"></a>Redis缓存雪崩、缓存击穿、缓存穿透</h3><p><strong>缓存雪崩</strong>：一般发生在将一批Key的过期时间都设置在同一时间节点上。而当它们一起过期的时候，大量的请求在缓存中找不到数据，直接打到了数据库上，数据库没法承载这么大的并发量直接崩掉了。就像雪崩一样，数据库崩掉了，与之相关的所有库的接口都没法使用了。用户此时还会不停地重试请求，即使DBA重启了数据库，这些大量的重试请求一样会再次使得数据库崩溃。</p>
<p>解决方案：将每个Key的过期时间在原有的基础上增加一个随机的值，使得缓存中的数据不会在同一时刻大量失效。</p>
<p><strong>缓存击穿</strong>：和缓存雪崩有点像。是缓存中的某个热点数据每时每刻都在接受大量的查询请求，当这个数据失效后，大量的查询请求会绕过缓存直接访问数据库，使得数据库崩溃。</p>
<p>解决方案：设置热点数据永不过期；或者使用互斥锁(第一个到数据库的查询会持有锁，其他的查询会等待，当第一个查询将数据存到缓存中后，接下来的查询会从缓存中读数据)</p>
<p><strong>缓存穿透</strong>：数据库和缓存中都没有的数据，而用户不断对这个数据发起请求。例如：一直查询id=-1的用户数据。每次请求都能绕过缓存直接打到数据库上，QPS高了，数据库就会崩溃。</p>
<p>解决方案：对参数做校验；使用布隆过滤器判断Key是否在数据库中存在</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/21/Redis/" data-id="clbaeg53b000m40tx7gmnfhz7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">内存数据库</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AD%98%E5%82%A8/" rel="tag">存储</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Kafka" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/20/Kafka/" class="article-date">
  <time datetime="2022-10-20T05:15:52.000Z" itemprop="datePublished">2022-10-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/20/Kafka/">Kafka</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>是一个分布式的流处理平台，支持消息的发布和订阅(类似消息队列)，支持数据实时处理，通过多副本分布式的方案保证消息的容错。</p>
<p>Kafka是一个分布式的流处理平台，支持消息的发布和订阅(类似消息队列)，支持数据实时处理，通过多副本分布式的方案保证消息的容错。</p>
<h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h3><p>Message： Kafka的基本数据单元</p>
<p>Batch：多个Message会放入同一Batch中再写入(减少网络开销)</p>
<p>Topics： Kafka的Message通过Topic（主题）进行分类，一个Topic包含多个Partitions</p>
<p>Partitions： 提交日志，Message以追加的方式写入Partition，一个Topic中的Partitions可以分布在不同服务器上，一个Partition也可以在多个服务器上备份</p>
<p>Producer：生产者，将消息分布到主题的不同分区上</p>
<p>Consumer：消费者，是消费群组的一部分，会消费消息。一个Partition只可以被同一个消费群组中的一个消费者读取，但可以被不同消费群组中所组成的多个消费者读取。</p>
<p>Broker：一个独立的Kafka服务器，接收生产者的消息，提交到磁盘保存，同时为消费者提供读取服务。</p>
<p>Cluster：由多个Broker组成的Kafka集群，一个Cluster中会选举出一个Broker作为集群控制器。在一个集群中，一个Partition从属于一个Broker，该Broker是该Partition的Leader，同时一个Partition也可以分配给多个Broker(分区复制)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/20/Kafka/" data-id="clbaeg537000c40tx8iwlgwg2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" rel="tag">消息队列</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-消息队列" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" class="article-date">
  <time datetime="2022-10-19T05:17:15.000Z" itemprop="datePublished">2022-10-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/">消息队列</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="消息队列的三个经典场景"><a href="#消息队列的三个经典场景" class="headerlink" title="消息队列的三个经典场景"></a>消息队列的三个经典场景</h3><p>异步、削峰、解耦</p>
<p>异步：一个业务流程因为需求的增加变长了，所对应的用户响应时间也变长。为了减少响应时间，采用消息队列去做异步请求，当一个步骤完成时，发送消息通知依赖它的其它步骤。</p>
<p>解耦：一个业务流程当增加新需求时，需要重新编码然后重新发布。而使用消息队列，只需要把一个需求“执行成功”的消息发送给其他部件，当新增部件时，只需要让这个部件去订阅这个成功的消息。解除了系统部件之间的耦合。</p>
<p>削峰：使用消息队列缓存消息，在请求峰值的时候，服务器会根据自己的处理能力去消费消息队列中的请求。</p>
<h3 id="消息队列的三个问题"><a href="#消息队列的三个问题" class="headerlink" title="消息队列的三个问题"></a>消息队列的三个问题</h3><p>系统复杂性、数据一致性、可用性</p>
<p>系统复杂性：引入中间件本来就会带来额外的技术成本，增高系统的复杂性</p>
<p>数据一致性：分布式服务的通病，消息队列中，一个业务完成后，只管通知其他的业务而不管其他的业务是否成功，可能会导致数据的不一致。（采用分布式事务解决）</p>
<p>可用性：如果中间价挂掉，依赖其他业务消息的业务全部没法正常执行。</p>
<h3 id="消息队列的主流实现"><a href="#消息队列的主流实现" class="headerlink" title="消息队列的主流实现"></a>消息队列的主流实现</h3><p>现在主要流行使用RocketMQ和Kafka。</p>
<p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/v2-8234b69f5e46550bc5d95db96251d8b6_1440w.webp" alt="img"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/19/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" data-id="clbaeg53g001440tx8xfx7faj" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" rel="tag">消息队列</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/" rel="tag">高并发</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-HTAP" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/17/HTAP/" class="article-date">
  <time datetime="2022-10-17T05:07:25.000Z" itemprop="datePublished">2022-10-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/">技术论文研读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/17/HTAP/">HTAP</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>​    <strong>原文</strong>：《HTAP Databases: What is New and What is Next》    </p>
<p>​    HTAP(Hybrid Transactional/Analystical Processing)是通过内存计算技术，在同一份内存数据上同时支持OLTP和OLAP的技术。传统的面向OLTP的数据库，在需要进行OLAP分析时，需要通过ETL技术将数据导过去，复杂、延迟性高、运维难度大。</p>
<p>​    HTAP适合在实时性要求更高的商业数据分析场景中使用。eg:购物节这种实时高并发场景下，实时提供分析业务给卖家，及时调整销售策略。</p>
<h3 id="Trade-off-for-HTAP"><a href="#Trade-off-for-HTAP" class="headerlink" title="Trade-off for HTAP"></a>Trade-off for HTAP</h3><p>HTAP数据库领域主要讨论工作负载隔离(Workload Isolation)和数据新鲜度(Data Freshness)两个特性的权衡。</p>
<h3 id="HTAP-数据库的主要架构"><a href="#HTAP-数据库的主要架构" class="headerlink" title="HTAP 数据库的主要架构"></a>HTAP 数据库的主要架构</h3><ul>
<li>主行存储+内存中列存储（Primary Row Store + InMemory Column Store）</li>
<li>分布式行存储+列存储副本（Distributed Row Store + Column Store Replica）</li>
<li>磁盘行存储+分布式列存储（Disk Row Store + Distributed Column Store）</li>
<li>主列存储+增量行存储（Primary Column Store + Delta Row Store）</li>
</ul>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>​    HTAP系统可以消除ETL过程从而使得在事务数据上进行实时分析成为可能，然而HTAP系统必须要在Workload Isolation(工作负载隔离)和Data Freshness(数据新鲜度)上进行平衡，因为其需要同时支持OLTP和OLAP操作。</p>
<p>​    作者以存储策略和架构对当前先进的HTAP系统进行分类，深挖了这些系统的事务处理过程、分析过程、数据同步、查询优化、资源分配。</p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><h4 id="BackGround"><a href="#BackGround" class="headerlink" title="BackGround"></a>BackGround</h4><p>​    当前各个组织处理的数据越来越多，且数据呈现出3V的特征(Velocity快速，Volume大量，Variety种类丰富)。对他们来说，使用一个单一的HTAP系统从而能有效地处理OLTP、OLAP操作是很必要的。例如对于电商来说，可以迅速及时地调整广告策略以推广更有希望畅销地商品；对于银行来说，可以及时根据用户的操作来调整风控等级。</p>
<h4 id="HTAP-Defination"><a href="#HTAP-Defination" class="headerlink" title="HTAP Defination"></a>HTAP Defination</h4><p>​    Hybrid Transactional/Analytical Processing(HTAP)是由Gartner在2014年提出的一种应用架构，其使用了内存计算的技术使得事务处理和数据分析任务可以在同一个内存数据块上并行。在2018年，Gartner扩展了HTAP的定义，将其定义为一个可以支持分析和事务处理并行的应用技术架构(不在局限于使用in-memory computing技术实现的HTAP)</p>
<h3 id="HTAP-DataBases"><a href="#HTAP-DataBases" class="headerlink" title="HTAP DataBases"></a>HTAP DataBases</h3><p>主要介绍了HTAP的四种架构</p>
<p>1）Primary Row Store+ In-Memory Column Store（主行存储+内存中列存储）</p>
<p>2）Distributed Row Store + Column Store Replica（分布式行存储+列存储副本）</p>
<p>3）Disk Row Store + Distributed Column Store（磁盘行存储+分布式列存储）</p>
<p>4）Primary Column Store + Delta Row Store（主列存储+增量行存储）</p>
<h4 id="Primary-Row-Store-In-Memory-Column-Store"><a href="#Primary-Row-Store-In-Memory-Column-Store" class="headerlink" title="Primary Row Store+ In-Memory Column Store"></a>Primary Row Store+ In-Memory Column Store</h4><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221018171745584.png" alt="image-20221018171745584" style="zoom:50%;" />

<p>在传统的行存的单机数据库的基础上，将所有的数据都存储到了主行存储中，同时在内存中增加了列存来加速AP查询，在行存部分也可以使用内存来进行优化。更新的数据会append到增量存储(Delta Store)中，增量存储会被merge到列存储中。这样既使用内存对AP来进行了加速，同时定期的增量存储与列存的合并也保证了数据的新鲜度。</p>
<p>Pros:</p>
<p>高AP吞吐量</p>
<p>高TP吞吐量</p>
<p>高数据新鲜度</p>
<p>Cons:</p>
<p>低AP扩展性</p>
<p>低工作负载隔离</p>
<p>Egs：</p>
<p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20221018172638031.png" alt="image-20221018172638031"></p>
<h4 id="Distributed-Row-Store-Column-Store-Replica"><a href="#Distributed-Row-Store-Column-Store-Replica" class="headerlink" title="Distributed Row Store + Column Store Replica"></a>Distributed Row Store + Column Store Replica</h4><p>面对大规模的负载处理。Master节点会在处理事务请求时将操作log异步发送到Slave节点上，一些Slave节点会被选取作为列存储服务器来加速查询。</p>
<p>Pros:</p>
<p>高工作负载隔离</p>
<p>高可扩展性</p>
<p>Cons：</p>
<p>低数据新鲜度</p>
<p>Egs:</p>
<p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20221018183839375.png" alt="image-20221018183839375"></p>
<h4 id="Disk-Row-Store-Distributed-Column-Store"><a href="#Disk-Row-Store-Distributed-Column-Store" class="headerlink" title="Disk Row Store + Distributed Column Store"></a>Disk Row Store + Distributed Column Store</h4><p>行存仍基于单机的行存数据库，列存置放到分布式的in-memory中，OLTP的工作负载和IMCS(in-memory column-store)高度集成。列数据从行数据中提取出来，hot data会被存放到IMCS中，而cold data会被交换到硬盘里。</p>
<p>Pros:</p>
<p>高工作负载隔离</p>
<p>高AP吞吐量和扩展性</p>
<p>Cons：</p>
<p>较低的数据新鲜度</p>
<p>Egs:</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221018190440599.png" alt="image-20221018190440599" style="zoom:50%;" />



<h4 id="Primary-Column-Store-Delta-Row-Store"><a href="#Primary-Column-Store-Delta-Row-Store" class="headerlink" title="Primary Column Store + Delta Row Store"></a>Primary Column Store + Delta Row Store</h4><p>使用Column作为主存来作为OLAP的基础，而使用增量存储来存储列数据从而支持OLTP。</p>
<p>Pros:</p>
<p>高数据新鲜度</p>
<p>高AP吞吐量</p>
<p>Cons:</p>
<p>低TP扩展性</p>
<p>低工作负载隔离</p>
<p>Egs：</p>
<p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221018190839708.png" alt="image-20221018190839708"></p>
<h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221018190925420.png" alt="image-20221018190925420"></p>
<h3 id="HTAP-Techniques"><a href="#HTAP-Techniques" class="headerlink" title="HTAP Techniques"></a>HTAP Techniques</h3><p>作者总结了五种HTAP Techniques:</p>
<ol>
<li>Transaction Processing</li>
<li>Analytical Processing</li>
<li>Data Synchronization</li>
<li>Query Optimization</li>
<li>Resource Scheduling</li>
</ol>
<p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221018191242172.png" alt="image-20221018191242172"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/17/HTAP/" data-id="clbaeg536000b40txe7649yak" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/OLAP/" rel="tag">OLAP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/OLTP/" rel="tag">OLTP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AD%98%E5%82%A8/" rel="tag">存储</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/">技术基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/">技术论文研读</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bert/" rel="tag">Bert</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Code-Completion/" rel="tag">Code Completion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KMP/" rel="tag">KMP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OLAP/" rel="tag">OLAP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OLTP/" rel="tag">OLTP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Raft/" rel="tag">Raft</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RocketMQ/" rel="tag">RocketMQ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SpringBoot/" rel="tag">SpringBoot</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ssh/" rel="tag">ssh</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/" rel="tag">云计算</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">内存数据库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%AE%97%E6%B3%95/" rel="tag">字符串算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%98%E5%82%A8/" rel="tag">存储</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%89%E5%85%A8/" rel="tag">安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/" rel="tag">文件系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B5%81%E8%AE%A1%E7%AE%97/" rel="tag">流计算</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" rel="tag">消息队列</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/" rel="tag">高并发</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Bert/" style="font-size: 10px;">Bert</a> <a href="/tags/Code-Completion/" style="font-size: 10px;">Code Completion</a> <a href="/tags/KMP/" style="font-size: 10px;">KMP</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/OLAP/" style="font-size: 10px;">OLAP</a> <a href="/tags/OLTP/" style="font-size: 10px;">OLTP</a> <a href="/tags/Raft/" style="font-size: 10px;">Raft</a> <a href="/tags/RocketMQ/" style="font-size: 10px;">RocketMQ</a> <a href="/tags/Spark/" style="font-size: 10px;">Spark</a> <a href="/tags/SpringBoot/" style="font-size: 10px;">SpringBoot</a> <a href="/tags/ssh/" style="font-size: 10px;">ssh</a> <a href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/" style="font-size: 10px;">云计算</a> <a href="/tags/%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 10px;">内存数据库</a> <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" style="font-size: 20px;">大数据</a> <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%AE%97%E6%B3%95/" style="font-size: 10px;">字符串算法</a> <a href="/tags/%E5%AD%98%E5%82%A8/" style="font-size: 17.5px;">存储</a> <a href="/tags/%E5%AE%89%E5%85%A8/" style="font-size: 12.5px;">安全</a> <a href="/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">文件系统</a> <a href="/tags/%E6%B5%81%E8%AE%A1%E7%AE%97/" style="font-size: 12.5px;">流计算</a> <a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" style="font-size: 15px;">消息队列</a> <a href="/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/" style="font-size: 10px;">高并发</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/11/">November 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/">October 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/11/24/KMP/">KMP</a>
          </li>
        
          <li>
            <a href="/2022/11/16/An%20Empirical%20Study%20on%20the%20Usage%20of%20BERT%20Models%20for%20Code%20Completion/">An Empirical Study on the Usage of BERT Models for Code Completion</a>
          </li>
        
          <li>
            <a href="/2022/11/12/Flink/">Flink</a>
          </li>
        
          <li>
            <a href="/2022/10/31/Raft-Exntended/">Raft-Exntended</a>
          </li>
        
          <li>
            <a href="/2022/10/27/RocketMQ/">RocketMQ</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 zh-CN<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>