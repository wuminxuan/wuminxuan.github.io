<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>吴旻轩的个人博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="吴旻轩的个人博客">
<meta property="og:url" content="http://wuminxuan.github.io/page/2/index.html">
<meta property="og:site_name" content="吴旻轩的个人博客">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="zh-CN">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="吴旻轩的个人博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">吴旻轩的个人博客</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://wuminxuan.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Storm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/15/Storm/" class="article-date">
  <time datetime="2022-10-15T05:13:02.000Z" itemprop="datePublished">2022-10-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/15/Storm/">Storm</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Storm是真正意义上的流处理框架。可以抽象成5个概念名词来理解，Topologies(拓扑)、Streams(流)、Spouts、Bolts、Stream groupings(分组策略)。</p>
<h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><h4 id="Topologies"><a href="#Topologies" class="headerlink" title="Topologies"></a>Topologies</h4><p>一个完整的Storm流处理程序，由Spout、Bolts通过Streams连接起来的有向无环图。</p>
<h4 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h4><p>一个Streams是一个无界的、以分布式方式并行创建和处理的Tuple序列(Tuple可以包含大多数基本类型以及自定义数据类型，是流数据的载体)，Stream就是一系列的Tuple。</p>
<h4 id="Spouts"><a href="#Spouts" class="headerlink" title="Spouts"></a>Spouts</h4><p>流数据的源头。</p>
<h4 id="Bolts"><a href="#Bolts" class="headerlink" title="Bolts"></a>Bolts</h4><p>流数据的处理单元</p>
<h4 id="Stream-groupings"><a href="#Stream-groupings" class="headerlink" title="Stream groupings"></a>Stream groupings</h4><p>决定Tuple发送到Bolts中哪一个Task的策略</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/15/Storm/" data-id="clbaeg53e000x40txfooc0ye1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B5%81%E8%AE%A1%E7%AE%97/" rel="tag">流计算</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Spark" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/15/Spark/" class="article-date">
  <time datetime="2022-10-15T04:18:20.000Z" itemprop="datePublished">2022-10-15</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/15/Spark/">Spark</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Spark-RDD"><a href="#Spark-RDD" class="headerlink" title="Spark RDD"></a>Spark RDD</h2><p>RDD（Resilient Distributed Datasets)，是Spark最基本的数据抽象，是只读的、分区记录的集合，支持并行操作，由外部数据集或其他RDD转换而来。</p>
<ul>
<li>一个RDD由一个或多个Partitions组成，每个Partitions会被一个计算任务处理，创建RDD时可以指定Partitions个数，默认采用程序分配到的CPU核心数。</li>
<li>RDD会保存依赖关系，RDD的转换会生成一个新的依赖关系，在部分Partitions数据丢失后，可以通过依赖关系重新计算这部分分区的数据，而不是对RDD所有分区重新计算。</li>
</ul>
<h3 id="RDD操作"><a href="#RDD操作" class="headerlink" title="RDD操作"></a>RDD操作</h3><p>RDD支持两种类型的操作：Transformation(转换，从现有数据集创建新的数据集)、Actions(在数据集上运行计算后将值返回到驱动程序)。RDD中的Transformation操作都是惰性的，只有当遇到Action操作后才会真正执行。</p>
<h3 id="宽依赖-amp-窄依赖"><a href="#宽依赖-amp-窄依赖" class="headerlink" title="宽依赖&amp;窄依赖"></a>宽依赖&amp;窄依赖</h3><p>RDD和它的父RDDs之间的依赖关系有两种：</p>
<p>Narrow Dependency(窄依赖)：父RDDs的一个Partition最多被子RDDs的一个Partition依赖。</p>
<p>Wide Dependency(宽依赖)：父RDDs的一个Parition可能被子RDDs的多个Paritions依赖。</p>
<p>窄依赖允许在一个集群节点上以流水线方式计算RDD之间的数据（不需要等待所有父分区的Partitions都在各自的集群节点上计算完成后，才进入到下一个计算）；而宽依赖需要等待所有父分区的数据都计算好后，才能进入下一个计算阶段。</p>
<p>窄依赖在丢失分区数据后，只需要对丢失Partition的父RDD中对应的Partition进行计算，并且不同节点间可以并行计算；而宽依赖需要计算所有的父分区数据。</p>
<h3 id="RDD算子"><a href="#RDD算子" class="headerlink" title="RDD算子"></a>RDD算子</h3><h4 id="Transformation算子"><a href="#Transformation算子" class="headerlink" title="Transformation算子"></a>Transformation算子</h4><table>
<thead>
<tr>
<th>Transformation 算子</th>
<th>Meaning（含义）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>map</strong>(<em>func</em>)</td>
<td>对原 RDD 中每个元素运用 <em>func</em> 函数，并生成新的 RDD</td>
</tr>
<tr>
<td><strong>filter</strong>(<em>func</em>)</td>
<td>对原 RDD 中每个元素使用<em>func</em> 函数进行过滤，并生成新的 RDD</td>
</tr>
<tr>
<td><strong>flatMap</strong>(<em>func</em>)</td>
<td>与 map 类似，但是每一个输入的 item 被映射成 0 个或多个输出的 items（ <em>func</em> 返回类型需要为 Seq ）。</td>
</tr>
<tr>
<td><strong>mapPartitions</strong>(<em>func</em>)</td>
<td>与 map 类似，但函数单独在 RDD 的每个分区上运行， <em>func</em>函数的类型为  Iterator&lt;T&gt; =&gt; Iterator&lt;U&gt; ，其中 T 是 RDD 的类型，即 RDD[T]</td>
</tr>
<tr>
<td><strong>mapPartitionsWithIndex</strong>(<em>func</em>)</td>
<td>与 mapPartitions 类似，但 <em>func</em> 类型为 (Int, Iterator&lt;T&gt;) =&gt; Iterator&lt;U&gt; ，其中第一个参数为分区索引</td>
</tr>
<tr>
<td><strong>sample</strong>(<em>withReplacement</em>, <em>fraction</em>, <em>seed</em>)</td>
<td>数据采样，有三个可选参数：设置是否放回（withReplacement）、采样的百分比（<em>fraction</em>）、随机数生成器的种子（seed）；</td>
</tr>
<tr>
<td><strong>union</strong>(<em>otherDataset</em>)</td>
<td>合并两个 RDD</td>
</tr>
<tr>
<td><strong>intersection</strong>(<em>otherDataset</em>)</td>
<td>求两个 RDD 的交集</td>
</tr>
<tr>
<td><strong>distinct</strong>([<em>numTasks</em>]))</td>
<td>去重</td>
</tr>
<tr>
<td><strong>groupByKey</strong>([<em>numTasks</em>])</td>
<td>按照 key 值进行分区，即在一个 (K, V) 对的 dataset 上调用时，返回一个 (K, Iterable&lt;V&gt;) <br/><strong>Note:</strong> 如果分组是为了在每一个 key 上执行聚合操作（例如，sum 或 average)，此时使用 <code>reduceByKey</code> 或 <code>aggregateByKey</code> 性能会更好<br><strong>Note:</strong> 默认情况下，并行度取决于父 RDD 的分区数。可以传入 <code>numTasks</code> 参数进行修改。</td>
</tr>
<tr>
<td><strong>reduceByKey</strong>(<em>func</em>, [<em>numTasks</em>])</td>
<td>按照 key 值进行分组，并对分组后的数据执行归约操作。</td>
</tr>
<tr>
<td><strong>aggregateByKey</strong>(<em>zeroValue</em>,<em>numPartitions</em>)(<em>seqOp</em>, <em>combOp</em>, [<em>numTasks</em>])</td>
<td>当调用（K，V）对的数据集时，返回（K，U）对的数据集，其中使用给定的组合函数和 zeroValue 聚合每个键的值。与 groupByKey 类似，reduce 任务的数量可通过第二个参数进行配置。</td>
</tr>
<tr>
<td><strong>sortByKey</strong>([<em>ascending</em>], [<em>numTasks</em>])</td>
<td>按照 key 进行排序，其中的 key 需要实现 Ordered 特质，即可比较</td>
</tr>
<tr>
<td><strong>join</strong>(<em>otherDataset</em>, [<em>numTasks</em>])</td>
<td>在一个 (K, V) 和 (K, W) 类型的 dataset 上调用时，返回一个 (K, (V, W)) pairs 的 dataset，等价于内连接操作。如果想要执行外连接，可以使用 <code>leftOuterJoin</code>, <code>rightOuterJoin</code> 和 <code>fullOuterJoin</code> 等算子。</td>
</tr>
<tr>
<td><strong>cogroup</strong>(<em>otherDataset</em>, [<em>numTasks</em>])</td>
<td>在一个 (K, V) 对的 dataset 上调用时，返回一个 (K, (Iterable&lt;V&gt;, Iterable&lt;W&gt;)) tuples 的 dataset。</td>
</tr>
<tr>
<td><strong>cartesian</strong>(<em>otherDataset</em>)</td>
<td>在一个 T 和 U 类型的 dataset 上调用时，返回一个 (T, U) 类型的 dataset（即笛卡尔积）。</td>
</tr>
<tr>
<td><strong>coalesce</strong>(<em>numPartitions</em>)</td>
<td>将 RDD 中的分区数减少为 numPartitions。</td>
</tr>
<tr>
<td><strong>repartition</strong>(<em>numPartitions</em>)</td>
<td>随机重新调整 RDD 中的数据以创建更多或更少的分区，并在它们之间进行平衡。</td>
</tr>
<tr>
<td><strong>repartitionAndSortWithinPartitions</strong>(<em>partitioner</em>)</td>
<td>根据给定的 partitioner（分区器）对 RDD 进行重新分区，并对分区中的数据按照 key 值进行排序。这比调用 <code>repartition</code> 然后再 sorting（排序）效率更高，因为它可以将排序过程推送到 shuffle 操作所在的机器。</td>
</tr>
</tbody></table>
<h4 id="Action算子"><a href="#Action算子" class="headerlink" title="Action算子"></a>Action算子</h4><table>
<thead>
<tr>
<th>Action（动作）</th>
<th>Meaning（含义）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>reduce</strong>(<em>func</em>)</td>
<td>使用函数<em>func</em>执行归约操作</td>
</tr>
<tr>
<td><strong>collect</strong>()</td>
<td>以一个 array 数组的形式返回 dataset 的所有元素，适用于小结果集。</td>
</tr>
<tr>
<td><strong>count</strong>()</td>
<td>返回 dataset 中元素的个数。</td>
</tr>
<tr>
<td><strong>first</strong>()</td>
<td>返回 dataset 中的第一个元素，等价于 take(1)。</td>
</tr>
<tr>
<td><strong>take</strong>(<em>n</em>)</td>
<td>将数据集中的前 <em>n</em> 个元素作为一个 array 数组返回。</td>
</tr>
<tr>
<td><strong>takeSample</strong>(<em>withReplacement</em>, <em>num</em>, [<em>seed</em>])</td>
<td>对一个 dataset 进行随机抽样</td>
</tr>
<tr>
<td><strong>takeOrdered</strong>(<em>n</em>, <em>[ordering]</em>)</td>
<td>按自然顺序（natural order）或自定义比较器（custom comparator）排序后返回前 <em>n</em> 个元素。只适用于小结果集，因为所有数据都会被加载到驱动程序的内存中进行排序。</td>
</tr>
<tr>
<td><strong>saveAsTextFile</strong>(<em>path</em>)</td>
<td>将 dataset 中的元素以文本文件的形式写入本地文件系统、HDFS 或其它 Hadoop 支持的文件系统中。Spark 将对每个元素调用 toString 方法，将元素转换为文本文件中的一行记录。</td>
</tr>
<tr>
<td><strong>saveAsSequenceFile</strong>(<em>path</em>)</td>
<td>将 dataset 中的元素以 Hadoop SequenceFile 的形式写入到本地文件系统、HDFS 或其它 Hadoop 支持的文件系统中。该操作要求 RDD 中的元素需要实现 Hadoop 的 Writable 接口。对于 Scala 语言而言，它可以将 Spark 中的基本数据类型自动隐式转换为对应 Writable 类型。(目前仅支持 Java and Scala)</td>
</tr>
<tr>
<td><strong>saveAsObjectFile</strong>(<em>path</em>)</td>
<td>使用 Java 序列化后存储，可以使用 <code>SparkContext.objectFile()</code> 进行加载。(目前仅支持 Java and Scala)</td>
</tr>
<tr>
<td><strong>countByKey</strong>()</td>
<td>计算每个键出现的次数。</td>
</tr>
<tr>
<td><strong>foreach</strong>(<em>func</em>)</td>
<td>遍历 RDD 中每个元素，并对其执行<em>fun</em>函数</td>
</tr>
</tbody></table>
<h2 id="Spark作业的不同提交形式"><a href="#Spark作业的不同提交形式" class="headerlink" title="Spark作业的不同提交形式"></a>Spark作业的不同提交形式</h2><p>主要分为Local模式、StandAlone模式、Yarn模式，其中StandAlone模式和Yarn模式分别支持client、cluster两种deploy-mode，默认Client。</p>
<p>Local模式提交的作业运行在本地；StandAlone模式采用Spark内置的集群模式，使用内置的资源管理器进行管理；Yarn模式将作业提交到Yarn上运行，此时不需要再启动Master节点和Worker节点，由Yarn进行任务调度。</p>
<p>Client Mode下，Spark Driver在提交作业的客户端进程中运行。(没有运行完成作业，不能关闭该客户端)。</p>
<p>Cluster Mode下，Spark Driver在应用程序的Master进程内运行。</p>
<h2 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark SQL"></a>Spark SQL</h2><p>Spark SQL是Spark的一个子模块，主要用于操作结构化数据。</p>
<h3 id="DataFrame-amp-DataSet"><a href="#DataFrame-amp-DataSet" class="headerlink" title="DataFrame &amp; DataSet"></a>DataFrame &amp; DataSet</h3><p>DataFrame是Spark SQL为了支持结构化数据的处理提供的一种数据结构，是一个由具名列组成的数据集，在概念上等同于关系数据库中的表，在多种语言中都定义了DataFrame的抽象。</p>
<p>DataSet相比于DataFrame，具备了强类型的特点，同时支持Lambda函数，但只能在Scala和Java中使用。</p>
<p>两者的主要区别在于：DataFrame对于Syntax Errors是编译时错误，而对于Analysis Error是运行时错误。DataSet中两者都是运行时错误。DataSet是Typed而DataFrame是Untyped，DataSet的类型由Case Class(Scala)或Java Bean(Java)来明确指定，所以字段名和类型错误在编译时就会被IDE发现。</p>
<h3 id="DataFrame-amp-DataSet-amp-RDDs"><a href="#DataFrame-amp-DataSet-amp-RDDs" class="headerlink" title="DataFrame &amp; DataSet &amp; RDDs"></a>DataFrame &amp; DataSet &amp; RDDs</h3><ul>
<li>RDDs适合非结构化处理，DataFrame和DataSet适合结构化数据和半结构化数据的处理。</li>
<li>DataFrame&amp;DataSet有统一的Structed API访问，RDDs更多在函数式编程场景中使用。</li>
</ul>
<h3 id="Spark-SQL的运行原理"><a href="#Spark-SQL的运行原理" class="headerlink" title="Spark SQL的运行原理"></a>Spark SQL的运行原理</h3><ol>
<li>编写DataFrame/Dataset/SQL代码；</li>
<li>如果代码没有编译错误，Spark会将其转换为一个逻辑计划；</li>
<li>Spark将此逻辑计划转换为物理计划，同时进行代码优化；</li>
<li>Spark在集群上执行这个物理计划，基于RDD操作。</li>
</ol>
<h2 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h2><p>​    Spark Streaming是Spark的一个子模块，可以从 HDFS，Flume，Kafka，Twitter 和 ZeroMQ 读取数据，也支持自定义数据源。</p>
<p>​    Spark Streaming提供离散流(DStream)的高级抽象，将数据流拆分成极小粒度的RDD，使其能得到接近于流处理的效果，但其本质上还是批处理(或者说是微批处理)。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/15/Spark/" data-id="clbaeg53e000u40txcpx3ald5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/" rel="tag">云计算</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-GFS" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/14/GFS/" class="article-date">
  <time datetime="2022-10-14T04:20:41.000Z" itemprop="datePublished">2022-10-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/">技术论文研读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/14/GFS/">GFS</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>GFS(Google File System)作为分布式文件系统，是google三剑客的基础。</p>
<h3 id="搜索引擎的支撑架构是什么？"><a href="#搜索引擎的支撑架构是什么？" class="headerlink" title="搜索引擎的支撑架构是什么？"></a>搜索引擎的支撑架构是什么？</h3><p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221011213043817.png" alt="image-20221011213043817"></p>
<h3 id="如何保存超大文件？"><a href="#如何保存超大文件？" class="headerlink" title="如何保存超大文件？"></a>如何保存超大文件？</h3><p>结构一：采用主从结构，在Master中保存索引信息，索引到对应数据Chunk的ChunkServer中。</p>
<p>Master+many ChunkServers</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221011213416474.png" alt="image-20221011213416474" style="zoom:50%;" />



<p>缺点：ChunkServer的任何改变都要通知Master</p>
<p>结构二：</p>
<p>减少结构一中Master的数据和流量，通过系统设计中耦合和聚合的思想，将具体的索引信息下发到ChunkServer中，而只在Master中保存数据到ChunkServer的记录，当本地数据有变化时，只在本地更改索引就可以了，Master不用修改。</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221011213803280.png" alt="image-20221011213803280" style="zoom:50%;" />



<h3 id="减少ChunkServer挂掉带来的损失"><a href="#减少ChunkServer挂掉带来的损失" class="headerlink" title="减少ChunkServer挂掉带来的损失"></a>减少ChunkServer挂掉带来的损失</h3><p>复制Chunks，在多个Server上保存相同的Chunk(3个通常)</p>
<h3 id="恢复损坏的Chunk"><a href="#恢复损坏的Chunk" class="headerlink" title="恢复损坏的Chunk"></a>恢复损坏的Chunk</h3><p>向Master求助，从存有相同Chunk的ChunkServer中请求数据。</p>
<h3 id="如何发现ChunkServer挂掉？"><a href="#如何发现ChunkServer挂掉？" class="headerlink" title="如何发现ChunkServer挂掉？"></a>如何发现ChunkServer挂掉？</h3><p>心跳机制</p>
<h3 id="ChunkServer挂掉后恢复数据"><a href="#ChunkServer挂掉后恢复数据" class="headerlink" title="ChunkServer挂掉后恢复数据"></a>ChunkServer挂掉后恢复数据</h3><p>当ChunkServer挂掉后，就在Master中Chunk-&gt;CS的映射关系表中删掉对应的项。同时Master中有一个修复进程，当观察到某个Chunk对应的ChunkServer数少于三个时，就会按照基于存活副本数的恢复策略，优先修复存活副本数少的Chunk。</p>
<h3 id="如何应对热点？"><a href="#如何应对热点？" class="headerlink" title="如何应对热点？"></a>如何应对热点？</h3><p>Master中的热点平衡进程会记录一些访问信息和资源利用率等，当副本过度繁忙时，将对应的Chunk复制到更多的ChunkServer中，基于ChunkServer的带宽和硬盘利用率来选择复制到哪个ChunkServer中。</p>
<h3 id="写文件过程？"><a href="#写文件过程？" class="headerlink" title="写文件过程？"></a>写文件过程？</h3><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221011215038558.png" alt="image-20221011215038558" style="zoom:50%;" />

<p>1、串行方式传递数据，按照距离客户端的远近考虑串行顺序，而不必先考虑谁是Primary谁是Replicas。</p>
<p>2、两阶段提交，先缓存数据，再由Primary发出指令完成写入。</p>
<p>3、当出现写错时，不处理错误，直接告诉客户端重试。（分布式系统中越想修复错误，越容易复杂化，奥卡姆剃刀原理）</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/14/GFS/" data-id="clbaeg534000840txhlkjfpun" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/" rel="tag">文件系统</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-HBase" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/13/HBase/" class="article-date">
  <time datetime="2022-10-13T05:06:03.000Z" itemprop="datePublished">2022-10-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/13/HBase/">HBase</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>HBase是一个构建在Hadoop上的面向列的数据库管理系统。Hadoop可以通过HDFS存储结构化、半结构化、非结构化的数据，但是它只能执行批处理，也只能以顺序存储的方式访问数据，无法对数据进行随机访问。而HBase基于Google Bigtable实现，将数据存储在HDFS上，客户端通过HBase实现对HDFS上数据的随机访问。</p>
<h3 id="HBase-Table"><a href="#HBase-Table" class="headerlink" title="HBase Table"></a>HBase Table</h3><p>HBase是面向列的，更准确地说，HBase是面向列族的。表的Schema仅定义列族，表有多个列族，每个列族包含有相关的任意数量的列，列由多个单元格组成，单元格可以存储多个版本的数据，多个版本的数据通过时间戳进行区分。</p>
<p>所有的列族都需要在创建表时进行定义，列族中的列使用列族名作为前缀，使用列限定符作为后缀。如courses:history是一个列，courses是列族，history则是具体的列限定符(也可以理解为列名)。列限定符不是表Schema的一部分，插入数据时可以动态创建列。</p>
<h3 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h3><h4 id="Regions"><a href="#Regions" class="headerlink" title="Regions"></a>Regions</h4><p>HBase Table中的所有行按照Row Key的字典序进行排序，一个表通过Row Keys的范围被水平切分成了多个Region，每个表开始只有一个Region，随着数据增加，Region会增大，当增大到一个阈值时，一个Region会被分为两个Regions。Region是HBase中分布式存储和负载均衡的最小单元，同一个Region不会被拆分存储到多个Region Server上。（Region 对应 Bigtable中的SSTable）</p>
<h4 id="Region-Server"><a href="#Region-Server" class="headerlink" title="Region Server"></a>Region Server</h4><p>Region Server运行在HDFS的DataNode上，有以下组件：</p>
<p>WAL(Write Ahead Log，预写日志)：内存数据恢复。</p>
<p>BlockCache：读缓存</p>
<p>MemStore：写缓存</p>
<p>HFile：将行数据按照KV形式存储在HDFS上。</p>
<h3 id="HBase系统架构"><a href="#HBase系统架构" class="headerlink" title="HBase系统架构"></a>HBase系统架构</h3><p>Master/Slave架构，由三种组件组成：</p>
<p>Zookeeper：保证集群中只有一个Master，存储Region的寻址入口，监控Region Server状态，存储HBase的Schema</p>
<p>Master：为Region Server分配Region，Region Server的负载均衡，Region Server的失效检测和恢复，GFS上的垃圾文件回收，处理Schema的更新请求。</p>
<p>Region Server：维护Region，处理IO请求；切分过大的Region。</p>
<p>HBase 使用 ZooKeeper 作为分布式协调服务来维护集群中的服务器状态。 Zookeeper 负责维护可用服务列表，并提供服务故障通知等服务</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/13/HBase/" data-id="clbaeg534000740txd52bbqvh" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AD%98%E5%82%A8/" rel="tag">存储</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-BigTable" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/12/BigTable/" class="article-date">
  <time datetime="2022-10-12T05:03:03.000Z" itemprop="datePublished">2022-10-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/">技术论文研读</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/12/BigTable/">BigTable</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>​    Bigtable 是一个分布式的结构化数据存储系统，它被设计用来处理海量数据：通常是分布在数千台普通服务器上的PB 级的数据。Google 的很多项目使用Bigtable 存储数据，包括Web 索引、GoogleEarth、Google Finance。<br>     Bigtable 已经实现了下面的几个目标：适用性广泛、可扩展、高性能和高可用性,Bigtable 是一个稀疏的、分布式的、持久化存储的多维度排序Map。</p>
<h3 id="如何保存一个很大的表？"><a href="#如何保存一个很大的表？" class="headerlink" title="如何保存一个很大的表？"></a>如何保存一个很大的表？</h3><p>将一个大表分成多个小表，每个小表里面是一些排过序的K，V串，用一个MetaData of Table保存每一个小表的存储位置。</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221013113258700.png" alt="image-20221013113258700" style="zoom:50%;" />



<h3 id="如何保存一个超大的表？"><a href="#如何保存一个超大的表？" class="headerlink" title="如何保存一个超大的表？"></a>如何保存一个超大的表？</h3><p>再递归地拆一层，大表变成Tablet，小表变成SSTable</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221013113523941.png" alt="image-20221013113523941" style="zoom:33%;" />

<p>Metadata of Table=a list of tablets</p>
<p>Tablet=a list of SSTables</p>
<p>SSTable=a list of sorted&lt;key,value&gt;</p>
<h3 id="如何写数据？"><a href="#如何写数据？" class="headerlink" title="如何写数据？"></a>如何写数据？</h3><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221013113809165.png" alt="image-20221013113809165" style="zoom:33%;" />

<p>通过先写入memTable（内存表）来加速，因为内存中是随机存取，更好排序</p>
<p>Tablet=memTable+a list of SSTables</p>
<h3 id="如何避免内存数据丢失？"><a href="#如何避免内存数据丢失？" class="headerlink" title="如何避免内存数据丢失？"></a>如何避免内存数据丢失？</h3><p>写入到memTable的同时，在tabletLog上添加一条更改的日志记录，虽然这时候往硬盘上写也会减速，但由于是顺序写入，所以相对较快，而且可能不是在本地写入，而是在远程，所以可能不会影响。</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221013115010963.png" alt="image-20221013115010963" style="zoom:50%;" />

<p>A Tablet=memTable + a list of SSTables + log</p>
<h3 id="如何加速读数据？"><a href="#如何加速读数据？" class="headerlink" title="如何加速读数据？"></a>如何加速读数据？</h3><p>建立索引，将SSTable拆成多个数据块。</p>
<img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221013115456847.png" alt="image-20221013115456847" style="zoom:33%;" />



<h3 id="继续加速？"><a href="#继续加速？" class="headerlink" title="继续加速？"></a>继续加速？</h3><p>使用BloomFilter过滤，判断一个数据在不在一个SSTable中。</p>
<p>SSTable=a list of 64k blocks + index +bloomfilter</p>
<p>布隆过滤器可以判断一个数据一定不在一个SSTable中，而不能判断一个数据是否一定在一个SSTable中。</p>
<h4 id="BloomFilter"><a href="#BloomFilter" class="headerlink" title="BloomFilter"></a>BloomFilter</h4><p>一个01组成的串，对于一个key，采用多种方式Hash，映射到串上的多个位置，映射到的位置变为1。查找时，通过同样的Hash方式映射到位置，如果所有的位置都为1，则说明key可能存在（因为可能别的key映射到的Hash冲突）；如果有一个位置不为1，则说明key肯定不存在。</p>
<h3 id="BigTable结构"><a href="#BigTable结构" class="headerlink" title="BigTable结构"></a>BigTable结构</h3><p><img src="https://wuminxuan-blog.oss-cn-hangzhou.aliyuncs.com/image-20221013122012438.png" alt="image-20221013122012438"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/12/BigTable/" data-id="clbaeg533000640tx4b7tam4p" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AD%98%E5%82%A8/" rel="tag">存储</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ssh" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/10/08/ssh/" class="article-date">
  <time datetime="2022-10-08T12:07:01.000Z" itemprop="datePublished">2022-10-08</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/">技术基础</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/10/08/ssh/">ssh</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>ssh(Secure SHell protocol)，在不安全网络上提供安全远程登录及其它安全网络服务。相比传统的节点间通信的方式，如telnet、ftp等，ssh提供了一个安全的信道。</p>
<h3 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h3><p>1.远程联机使用shell服务器(最常用的一种)</p>
<p>2.类似ftp的sftp-server，更安全的FTP服务</p>
<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>1.服务器生成公钥、私钥存放在指定目录下（通常/etc/ssh/ssh_host+*）</p>
<p>2.用户请求联机</p>
<p>3.服务器传送公钥给客户端(明码传送，公钥不担心泄露)</p>
<p>4.客户端接收到服务器的公钥后，首先搜索之前是否有过相同的公钥，如果没有过，则提醒用户询问是否连接</p>
<p>5.生成会话密钥（对称加密的加密强度高，难以破解，但密钥本身的传输需要通过明文进行，密钥本身可能会泄露；非对称加密则使用公钥、私钥来分别加密、解密，但加解密速度慢。所以ssh结合这两者，首先使用非对称加密在会话初始阶段进行密钥协商，此后使用协商出来的密钥进行对称加密）</p>
<p>6.在加密信道上进行通信</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://wuminxuan.github.io/2022/10/08/ssh/" data-id="clbaeg53f001040txasjt6fa5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ssh/" rel="tag">ssh</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%AE%89%E5%85%A8/" rel="tag">安全</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/">技术基础</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/">技术论文研读</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bert/" rel="tag">Bert</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Code-Completion/" rel="tag">Code Completion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KMP/" rel="tag">KMP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OLAP/" rel="tag">OLAP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OLTP/" rel="tag">OLTP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Raft/" rel="tag">Raft</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RocketMQ/" rel="tag">RocketMQ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spark/" rel="tag">Spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SpringBoot/" rel="tag">SpringBoot</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ssh/" rel="tag">ssh</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/" rel="tag">云计算</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">内存数据库</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%AE%97%E6%B3%95/" rel="tag">字符串算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AD%98%E5%82%A8/" rel="tag">存储</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%AE%89%E5%85%A8/" rel="tag">安全</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/" rel="tag">文件系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B5%81%E8%AE%A1%E7%AE%97/" rel="tag">流计算</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" rel="tag">消息队列</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/" rel="tag">高并发</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Bert/" style="font-size: 10px;">Bert</a> <a href="/tags/Code-Completion/" style="font-size: 10px;">Code Completion</a> <a href="/tags/KMP/" style="font-size: 10px;">KMP</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/OLAP/" style="font-size: 10px;">OLAP</a> <a href="/tags/OLTP/" style="font-size: 10px;">OLTP</a> <a href="/tags/Raft/" style="font-size: 10px;">Raft</a> <a href="/tags/RocketMQ/" style="font-size: 10px;">RocketMQ</a> <a href="/tags/Spark/" style="font-size: 10px;">Spark</a> <a href="/tags/SpringBoot/" style="font-size: 10px;">SpringBoot</a> <a href="/tags/ssh/" style="font-size: 10px;">ssh</a> <a href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/" style="font-size: 10px;">云计算</a> <a href="/tags/%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 10px;">内存数据库</a> <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" style="font-size: 20px;">大数据</a> <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%AE%97%E6%B3%95/" style="font-size: 10px;">字符串算法</a> <a href="/tags/%E5%AD%98%E5%82%A8/" style="font-size: 17.5px;">存储</a> <a href="/tags/%E5%AE%89%E5%85%A8/" style="font-size: 12.5px;">安全</a> <a href="/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/" style="font-size: 10px;">文件系统</a> <a href="/tags/%E6%B5%81%E8%AE%A1%E7%AE%97/" style="font-size: 12.5px;">流计算</a> <a href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" style="font-size: 15px;">消息队列</a> <a href="/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/" style="font-size: 10px;">高并发</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/11/">November 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/">October 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/11/24/KMP/">KMP</a>
          </li>
        
          <li>
            <a href="/2022/11/16/An%20Empirical%20Study%20on%20the%20Usage%20of%20BERT%20Models%20for%20Code%20Completion/">An Empirical Study on the Usage of BERT Models for Code Completion</a>
          </li>
        
          <li>
            <a href="/2022/11/12/Flink/">Flink</a>
          </li>
        
          <li>
            <a href="/2022/10/31/Raft-Exntended/">Raft-Exntended</a>
          </li>
        
          <li>
            <a href="/2022/10/27/RocketMQ/">RocketMQ</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 zh-CN<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>